{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0711ae9-c2c4-4c07-a868-1a296557e0e2",
   "metadata": {},
   "source": [
    "## Thesis Relevant Comments Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597149d-9349-4fef-8cf4-20cf275082ce",
   "metadata": {},
   "source": [
    "After the first filtering step, all comments marked as **“not relevant”** were rechecked to ensure no potentially useful comments were missed.\n",
    "\n",
    "This time, each comment was reclassified into one of three categories:\n",
    "\n",
    "- **YES** – Clearly relevant to sportswashing  \n",
    "- **MAYBE** – Ambiguous but possibly relevant  \n",
    "- **DEFINITLY NOT** – Still not relevant  \n",
    "\n",
    "This extra step helps catch borderline or nuanced comments that might still offer value for understanding how sportswashing narratives are discussed, especially when initial filters were too strict or missed context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1591bf8-179b-4436-8895-3e8302b72f32",
   "metadata": {},
   "source": [
    "Below is the extraction of each batch processed from the initial stage with the Yes and No counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1c07d-0356-461e-b306-fc4743aaa4e8",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164ac04-2f60-4ae6-ae30-9e672b58118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc5c9c-f8ef-4051-87aa-73bae6846ef0",
   "metadata": {},
   "source": [
    "## Creating json files for the no responses and resubmitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be851f4-715b-4095-be9d-caee09023ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting OpenAI API Key\n",
    "openai.api_key = \"**************\" \n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# Loading in the CSV File\n",
    "input_csv = \"YouTube_Comments_No.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Ensuring Rewritten Comment column exists\n",
    "if \"Rewritten Comment\" not in df.columns:\n",
    "    raise KeyError(\"Column 'Rewritten Comment' not found in CSV.\")\n",
    "\n",
    "# Splitting into 2 equal parts\n",
    "split_idx = math.ceil(len(df) / 2)\n",
    "df_batches = [df.iloc[:split_idx], df.iloc[split_idx:]]\n",
    "\n",
    "# Output JSONL file names\n",
    "batch_files = [\"batch_check_no_comments_1.jsonl\", \"batch_check_no_comments_2.jsonl\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fbf9ea-2958-46b0-a657-af5d2e5028ae",
   "metadata": {},
   "source": [
    "### Define sportswashing prompt & create JSONL batch files (YES/MAYBE/DEFINITELY NOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33c4093-c547-40e4-9737-a2a2aa2d2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch JSONL file 'batch_check_no_comments_1.jsonl' created successfully!\n",
      "Batch JSONL file 'batch_check_no_comments_2.jsonl' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Defining the prompt function\n",
    "def generate_prompt(comment):\n",
    "    return f\"\"\"\n",
    "**Definition of Sportswashing:**  \n",
    "- When sports are used to improve a country’s reputation while hiding **human rights abuses, corruption, or political issues**.\n",
    "- Example: **Gulf states** (Saudi Arabia, Qatar, UAE) investing in sports, hosting events (FIFA, F1), or owning clubs (Man City, PSG, Newcastle).  \n",
    "\n",
    "**Classification Rules:**  \n",
    "- `YES`: Mentions sportswashing, Gulf investments, corruption, political influence, financial takeovers, or criticism/support of Gulf involvement.  \n",
    "- `MAYBE`: Unclear connection but mentions Middle Eastern entities, Gulf countries, or potential geopolitical influence.  \n",
    "- `DEFINITELY NOT`: Clearly about **match performance, goals, players, or unrelated topics** (e.g., \"That was a great goal!\", \"This team played well\").  \n",
    "\n",
    "**YouTube Comment (Rewritten for Clarity):**  \n",
    "\\\"{comment}\\\"  \n",
    "\n",
    "**Instructions:**  \n",
    "- Respond **ONLY** with `YES`, `MAYBE`, or `DEFINITELY NOT`, nothing else.  \n",
    "- If uncertain, **lean toward `YES`** if the comment references any political, financial, or ethical aspect of sports.  \n",
    "\"\"\"\n",
    "\n",
    "# Creating JSONL batch files in OpenAI's batch format\n",
    "for batch_idx, (batch_df, batch_file) in enumerate(zip(df_batches, batch_files), start=1):\n",
    "    with open(batch_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Writing {batch_file}\", unit=\"comment\"):\n",
    "            task = {\n",
    "                \"custom_id\": str(row[\"Comment_ID\"]),\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",  \n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are verifying if YouTube comments are actually unrelated to sportswashing and Gulf influence in sports.\"},\n",
    "                        {\"role\": \"user\", \"content\": generate_prompt(row[\"Rewritten Comment\"])}\n",
    "                    ],\n",
    "                    \"temperature\": 0,  \n",
    "                    \"max_tokens\": 5  \n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(task) + \"\\n\")\n",
    "    print(f\"Batch JSONL file '{batch_file}' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5cf07-2648-41b3-a14e-8a85a32acb25",
   "metadata": {},
   "source": [
    "### Submit first batch now, wait 5 hours, then submit second batch (OpenAI Batch API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab22e024-e38c-454f-9a97-acac0fb57612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_check_no_comments_1.jsonl: 100%|█| 42130/42130 [00:05<00:00, 72]\n",
      "Batch JSONL file 'batch_check_no_comments_1.jsonl' created successfully!\n",
      "Writing batch_check_no_comments_2.jsonl: 100%|█| 42129/42129 [00:04<00:00, 94]\n",
      "Batch JSONL file 'batch_check_no_comments_2.jsonl' created successfully!\n",
      "\n",
      "Submitting first batch file: batch_check_no_comments_1.jsonl\n",
      "First batch submitted successfully! Job ID: batch_67d754de87e88190bbb088b9e4bbc0d8\n",
      "\n",
      "Submitting second batch file: batch_check_no_comments_2.jsonl\n",
      "Second batch submitted successfully! Job ID: batch_67d79b46760c8190831ff32f9d5baf16\n"
     ]
    }
   ],
   "source": [
    "# Submitting the first batch immediately\n",
    "first_batch_file = batch_files[0]\n",
    "if os.path.exists(first_batch_file):\n",
    "    try:\n",
    "        print(f\"\\nSubmitting first batch file: {first_batch_file}\")\n",
    "        with open(first_batch_file, \"rb\") as f:\n",
    "            batch_file_upload = client.files.create(file=f, purpose=\"batch\")\n",
    "        batch_job = client.batches.create(\n",
    "            input_file_id=batch_file_upload.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(f\"First batch submitted successfully! Job ID: {batch_job.id}\")\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"OpenAI API error submitting first batch: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error submitting first batch: {e}\")\n",
    "\n",
    "# Waiting 5 hours before submitting the second batch\n",
    "time.sleep(5 * 60 * 60)  # 5 hours in seconds\n",
    "\n",
    "# Submitting the second batch\n",
    "second_batch_file = batch_files[1]\n",
    "if os.path.exists(second_batch_file):\n",
    "    try:\n",
    "        print(f\"\\nSubmitting second batch file: {second_batch_file}\")\n",
    "        with open(second_batch_file, \"rb\") as f:\n",
    "            batch_file_upload = client.files.create(file=f, purpose=\"batch\")\n",
    "        batch_job = client.batches.create(\n",
    "            input_file_id=batch_file_upload.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(f\"Second batch submitted successfully! Job ID: {batch_job.id}\")\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"OpenAI API error submitting second batch: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error submitting second batch: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335fed9f-f6a2-46fb-ad22-e1a9c5419628",
   "metadata": {},
   "source": [
    "### Count of Yes/no comments from Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19bfd8d7-19a5-43f4-b51b-9dead2829ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'YES' responses: 9051\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"responses_yes.csv\")\n",
    "\n",
    "# Count YES responses\n",
    "yes_count = (df['response'] == 'YES').sum()\n",
    "\n",
    "print(f\"Number of 'YES' responses: {yes_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19491af6-edf5-49bc-b0fd-bdf412f42c53",
   "metadata": {},
   "source": [
    "### Split 'Maybe' and 'Definitely Not' Comments for Further Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47133d72-8b8e-4cf4-a4a2-66a96675da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files created: comments_maybe.csv & comments_definitely_not.csv\n"
     ]
    }
   ],
   "source": [
    "# Loading the Data\n",
    "input_csv = \"final_maybe_definitely_not.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Separating the Data by Response Column\n",
    "df_maybe = df[df[\"response\"].str.lower() == \"maybe\"].copy()\n",
    "df_definitely_not = df[df[\"response\"].str.lower() == \"definitely not\"].copy()\n",
    "\n",
    "# Saving as separate CSV files\n",
    "df_maybe.to_csv(\"comments_maybe.csv\", index=False)\n",
    "df_definitely_not.to_csv(\"comments_definitely_not.csv\", index=False)\n",
    "\n",
    "print(\"CSV files created: comments_maybe.csv & comments_definitely_not.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741034aa-84a1-4f5f-903a-d91a8baa692c",
   "metadata": {},
   "source": [
    "Compare 'Maybe' Comments to Transcripts Using SBERT\n",
    "\n",
    "This step checks whether “maybe” comments are actually relevant by comparing them to their associated video transcripts.\n",
    "\n",
    "- Loads the `comments_maybe.csv` and transcript file.\n",
    "- Encodes both the comment and transcript sentences using **SBERT**.\n",
    "- Finds the **top 5 most similar transcript sentences** for each comment based on cosine similarity.\n",
    "- Sends this along with the comment to **GPT-4o**, asking whether the comment is relevant based on transcript context and predefined criteria.\n",
    "- Outputs a `batch_maybe_transcript_comparison.jsonl` file, ready to be submitted to the OpenAI batch endpoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65df5e6-ec62-49df-a309-1ef0247df0e2",
   "metadata": {},
   "source": [
    "### Load comments & transcripts, initialize SBERT, and validate schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef331cc8-c7e6-4787-b5aa-b8347b558a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded comments file: comments_maybe.csv (21031 rows)\n",
      "Loaded transcripts file: Processed_YouTube_Transcripts.csv (162 rows)\n",
      "Loading SBERT model...\n",
      "SBERT model loaded successfully.\n",
      "Column validation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "input_csv = \"comments_maybe.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "print(f\"Loaded comments file: {input_csv} ({len(df)} rows)\")\n",
    "\n",
    "transcript_csv = \"Processed_YouTube_Transcripts.csv\"\n",
    "df_transcripts = pd.read_csv(transcript_csv)\n",
    "print(f\"Loaded transcripts file: {transcript_csv} ({len(df_transcripts)} rows)\")\n",
    "\n",
    "# Loading the SBERT Model\n",
    "print(\"Loading SBERT model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(\"SBERT model loaded successfully.\")\n",
    "\n",
    "# Ensuring the Required Columns Exists\n",
    "required_columns = [\"custom_id\", \"Rewritten Comment\", \"Video_ID\"]\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    raise KeyError(f\" Missing required columns in comments CSV: {required_columns}\")\n",
    "\n",
    "if \"Video_ID\" not in df_transcripts.columns or \"Transcript\" not in df_transcripts.columns:\n",
    "    raise KeyError(\" Required columns ('Video_ID', 'Transcript') missing from transcript CSV.\")\n",
    "\n",
    "print(\"Column validation completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca32592-1201-4ea3-9ca2-268cf6dfeca7",
   "metadata": {},
   "source": [
    "### Compute comment & transcript embeddings, then define top-5 transcript similarity helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3426f1da-cd68-4a48-9f44-e45521849815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding all comments in batch...\n",
      "Precomputing transcript embeddings...\n",
      "Processing Transcripts: 100%|█████████| 162/162 [00:47<00:00, 3.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Precompute SBERT Embeddings for All Comments\n",
    "print(\"Encoding all comments in batch...\")\n",
    "comment_embeddings = model.encode(df[\"Rewritten Comment\"].tolist(), convert_to_tensor=True)\n",
    "df[\"comment_embedding\"] = list(comment_embeddings)  # Storing embeddings in DataFrame\n",
    "print(\"Comment embeddings computed successfully.\")\n",
    "\n",
    "# Precompute Transcript Embeddings\n",
    "transcript_embeddings = {}\n",
    "print(\"Precomputing transcript embeddings...\")\n",
    "for _, row in tqdm(df_transcripts.iterrows(), total=len(df_transcripts), desc=\"Processing Transcripts\"):\n",
    "    video_id = row[\"Video_ID\"]\n",
    "    transcript_text = row[\"Transcript\"]\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', transcript_text)\n",
    "    \n",
    "    top_k = min(5, len(sentences))  # Always select 5 sentences, or fewer if transcript is shorter\n",
    "    \n",
    "    if len(sentences) == 0:\n",
    "        transcript_embeddings[video_id] = ([\"No meaningful sentences\"] * top_k, torch.tensor([0.0]))\n",
    "    else:\n",
    "        transcript_embeddings[video_id] = (sentences, model.encode(sentences, convert_to_tensor=True))\n",
    "print(\"Transcript embeddings computed successfully.\")\n",
    "\n",
    "# Function to Get Top 5 Similar Sentences\n",
    "def get_top_similar_sentences(comment_embedding, video_id):\n",
    "    if video_id not in transcript_embeddings:\n",
    "        return [\"No transcript found\"] * 5, 0.0  # Ensure at least 5 elements\n",
    "\n",
    "    transcript_sentences, transcript_embedding = transcript_embeddings[video_id]\n",
    "    similarities = util.pytorch_cos_sim(comment_embedding, transcript_embedding)[0]\n",
    "    max_similarity = torch.max(similarities).item()\n",
    "    \n",
    "    top_n = min(5, len(transcript_sentences))  # Always use 5 sentences\n",
    "    top_indices = torch.topk(similarities, k=top_n).indices\n",
    "    top_sentences = [transcript_sentences[i] for i in top_indices]\n",
    "\n",
    "    while len(top_sentences) < 5:\n",
    "        top_sentences.append(\"N/A\")\n",
    "\n",
    "    return top_sentences, max_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec0135-ad8f-4dba-be7d-91d75903eda1",
   "metadata": {},
   "source": [
    "### Generate JSONL batch for comment–transcript relevance classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "635b1d88-2c37-4e84-b757-c70b42f03351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comments...\n",
      "Processing comments: 100%|█████████| 21031/21031 [00:10<00:00, 2075.06it/s]\n",
      "JSONL file created: batch_maybe_transcript_comparison.json\n"
     ]
    }
   ],
   "source": [
    "# Process Comments\n",
    "output_jsonl = \"batch_maybe_transcript_comparison.jsonl\"\n",
    "print(\"Processing comments...\")\n",
    "\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing comments\"):\n",
    "        comment_id = str(row[\"custom_id\"])\n",
    "        rewritten_comment = row[\"Rewritten Comment\"]\n",
    "        video_id = row[\"Video_ID\"]\n",
    "        comment_embedding = row[\"comment_embedding\"]\n",
    "\n",
    "        top_sentences, _ = get_top_similar_sentences(comment_embedding, video_id)\n",
    "\n",
    "        task = {\n",
    "            \"custom_id\": comment_id,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are analyzing YouTube comments by comparing them to their video transcripts. Your task is to determine whether the transcript provides meaningful context for the comment.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "**Comment:** \"{rewritten_comment}\"\n",
    "\n",
    "**Top 5 Transcript Sentences:**\n",
    "\"\"\" + \"\\n\".join([f\"- {sentence}\" for sentence in top_sentences]) + \"\"\"\n",
    "\n",
    "### Task:\n",
    "Determine whether this comment is relevant to discussions about sportswashing, human rights, financial ethics, corruption, or geopolitical motives.\n",
    "Additionally, if the comment makes a **positive or negative statement, opinion, or fact** about the **Middle East**, then it is considered relevant.\n",
    "\n",
    "### Instructions:\n",
    "- Respond **\"YES\"** if the comment relates to **any** of the above topics or expresses a **positive/negative statement about the Middle East**.\n",
    "- Respond **\"NO\"** if the comment is **only about match performance, players, goals, or unrelated topics**.\n",
    "\n",
    "### **Final Response Format:**  \n",
    "Respond **ONLY** with \"YES\" or \"NO\", nothing else.\n",
    "\"\"\"}\n",
    "                ],\n",
    "                \"temperature\": 0.0,\n",
    "                \"max_tokens\": 5\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "print(f\"JSONL file created: {output_jsonl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cb20a-18be-4a36-8a0b-e2c764b29fdf",
   "metadata": {},
   "source": [
    "### Upload JSONL batch to OpenAI and submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f8b2bbf-d28f-4715-bac3-e0e4c8d75350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading batch file: batch_maybe_transcript_comparison.jsonl\n",
      "Uploading batch_maybe_transcript_comparison.jsonl: 100%|██████████| 114M/114M [0:00:00]\n",
      "batch_maybe_transcript_comparison.jsonl uploaded successfully. File ID: file-8VLhAMWoB3M6LDL9EvUY79\n",
      "Batch submitted successfully! Job ID: batch_67d9fa2dacd881909410aeb7f8ddf162\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"******************\"  \n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# Path to Batch JSONL File\n",
    "batch_file = \"batch_maybe_transcript_comparison.jsonl\"\n",
    "\n",
    "# Uploading & Submitting the Batch\n",
    "if not os.path.exists(batch_file):\n",
    "    raise FileNotFoundError(f\" {batch_file} not found. Check the file path.\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\n Uploading batch file: {batch_file}\")\n",
    "\n",
    "    # Uploading the JSONL batch file\n",
    "    file_size = os.path.getsize(batch_file)\n",
    "    with tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=f\" Uploading {batch_file}\") as pbar:\n",
    "        with open(batch_file, \"rb\") as f:\n",
    "            batch_file_upload = client.files.create(file=f, purpose=\"batch\")\n",
    "            pbar.update(file_size)  # Update progress bar when upload completes\n",
    "\n",
    "    print(f\" {batch_file} uploaded successfully. File ID: {batch_file_upload.id}\")\n",
    "\n",
    "    # Submitting Batch Job to OpenAI\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_file_upload.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"  \n",
    "    )\n",
    "\n",
    "    print(f\" Batch submitted successfully! Job ID: {batch_job.id}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error submitting batch: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc478a7-8f10-40c7-9904-f7fc56ad362e",
   "metadata": {},
   "source": [
    "### Download batch output files from OpenAI and save as JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f80ee5c-78af-436d-9c99-ac75352bb7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded: file-FANQa3jqFsxWTQPsQYiHXN.jsonl\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"******************\"  \n",
    "\n",
    "# List of output file IDs from completed batches\n",
    "output_file_ids = [\"file-FANQa3jqFsxWTQPsQYiHXN\",\n",
    "]\n",
    "\n",
    "# Download each output file properly\n",
    "for file_id in output_file_ids:\n",
    "    file_response = openai.files.content(file_id)\n",
    "\n",
    "    # Saving the file locally in binary mode\n",
    "    output_filename = f\"{file_id}.jsonl\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        for chunk in file_response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "    \n",
    "    print(f\" File downloaded: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5476d77-f733-4a8c-a8c0-9232164acf1c",
   "metadata": {},
   "source": [
    "### Count of Yes/No Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fca31f7-ddb0-453f-8572-c1b5da362a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'YES' responses: 17824\n",
      "Number of blank responses: 3207\n"
     ]
    }
   ],
   "source": [
    "# List of JSONL files\n",
    "input_files = [\n",
    "    \"file-FANQa3jqFsxWTQPsQYiHXN.jsonl\"\n",
    "]\n",
    "\n",
    "# Reading and combine all files into one DataFrame\n",
    "data = []\n",
    "for file_name in input_files:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        data.extend([\n",
    "            {\n",
    "                \"custom_id\": obj.get(\"custom_id\", \"\"),\n",
    "                \"response\": obj.get(\"response\", {}).get(\"body\", {}).get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "            }\n",
    "            for obj in map(json.loads, f)\n",
    "        ])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Count YES vs NO\n",
    "print(f\"Number of 'YES' responses: {(df['response'] == 'YES').sum()}\")\n",
    "print(f\"Number of 'NO' responses: {(df['response'] == 'NO').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255f65b-9f60-4122-8bc2-daa51b533a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
