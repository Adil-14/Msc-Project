{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d01f1b-14de-46b3-bb0f-cfe9b450fb42",
   "metadata": {},
   "source": [
    "# Agreed with Transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfacaa-992d-4b73-8479-1f7c83efb59b",
   "metadata": {},
   "source": [
    "- This notebook focuses on analysing comments that were influenced by the video's transcript.\n",
    "- I start by filtering the dataset to only include those influenced comments.\n",
    "- Then I load the corresponding video transcripts and split each one into individual sentences.\n",
    "- I use SBERT to generate sentence embeddings for all transcript sentences, which allows for efficient comparison later.\n",
    "- These embeddings are then used to match each influenced comment to the most similar sentence in the transcript.\n",
    "- The matched pairs are sent through OpenAI's batch processing to determine whether the comment agrees, disagrees, or is neutral toward the transcript content.\n",
    "- The results are stored in a new `Agreed_with_Transcript` column for each comment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863b5a9-50ce-4123-a88a-aa308470778c",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb602a55-5d26-4a86-b43f-a388d4a2ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a570612d-2d1f-4d76-9b47-19b5d9fc7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved influenced comments to Influenced_Comments.csv\n"
     ]
    }
   ],
   "source": [
    "# Load merged dataset with influence labels\n",
    "df = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence.csv\")\n",
    "\n",
    "# Keep only rows where comment was influenced by transcript\n",
    "df_influenced = df[df[\"Influenced_by_Transcript\"] == 1]\n",
    "\n",
    "# Save filtered file\n",
    "df_influenced.to_csv(\"Influenced_Comments.csv\", index=False)\n",
    "print(\"Saved influenced comments to Influenced_Comments.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9907f-6c9c-4e6e-88b8-99a433b1eb2e",
   "metadata": {},
   "source": [
    "### Generate Sentence Embeddings for Video Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "272e9511-eead-4326-bd1f-4c612c7e4f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding transcripts: 100%|█████████████████████| 162/162 [00:45<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load transcript dataset\n",
    "df_transcripts = pd.read_csv(\"Processed_YouTube_Transcripts.csv\")\n",
    "\n",
    "# Load SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Precompute transcript sentence embeddings\n",
    "transcript_embeddings = {}\n",
    "for _, row in tqdm(df_transcripts.iterrows(), total=len(df_transcripts), desc=\"Encoding transcripts\"):\n",
    "    video_id = row[\"Video_ID\"]\n",
    "    transcript_text = row[\"Transcript\"]\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', transcript_text.strip())\n",
    "\n",
    "    if not sentences:\n",
    "        continue\n",
    "\n",
    "    transcript_embeddings[video_id] = (\n",
    "        sentences,\n",
    "        model.encode(sentences, convert_to_tensor=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3dbe1-f861-4581-b608-4b561dfaba2c",
   "metadata": {},
   "source": [
    "### Retrieve Top 5 Most Similar Transcript Sentences for a Comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ba1790-84c4-41f7-9cdb-adc23adc0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similar_sentences(comment, video_id):\n",
    "    if video_id not in transcript_embeddings:\n",
    "        return [\"No transcript found\"] * 5\n",
    "\n",
    "    sentences, embeddings = transcript_embeddings[video_id]\n",
    "    comment_embedding = model.encode(comment, convert_to_tensor=True)\n",
    "    similarities = util.pytorch_cos_sim(comment_embedding, embeddings)[0]\n",
    "    top_indices = torch.topk(similarities, k=min(5, len(sentences))).indices\n",
    "    return [sentences[i] for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719632b-a334-4738-a708-382892e2f8d5",
   "metadata": {},
   "source": [
    "### Building Token-Limited Prompts for Checking Agreement Between Comments and Transcripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16c33c18-d9ef-4e16-b146-0c2acd2e2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-4o Mini tokenizer\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "def get_token_count(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def build_prompt_within_token_limit(comment, video_id, max_total_tokens=4000, max_sentence_chars=200):\n",
    "    top_sentences = get_top_similar_sentences(comment, video_id)\n",
    "    top_sentences = [s[:max_sentence_chars] for s in top_sentences]\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are helping a researcher check if a YouTube comment agrees with the video transcript. \"\n",
    "        \"Some comments support, oppose, or are unrelated to the transcript. Judge the comment in context.\"\n",
    "    )\n",
    "\n",
    "    for n in range(5, 0, -1):\n",
    "        selected = top_sentences[:n]\n",
    "        transcript_block = \"\\n\".join(f\"- {s}\" for s in selected)\n",
    "\n",
    "        user_prompt = f\"\"\"Comment: \"{comment}\"\\nTranscript:\\n{transcript_block}\\n\\nDoes this comment agree with the transcript?\\n\\nReply ONLY with:\\n1 = agrees\\n-1 = disagrees\\n0 = neutral\"\"\"\n",
    "\n",
    "        total_tokens = get_token_count(system_prompt) + get_token_count(user_prompt)\n",
    "        if total_tokens <= max_total_tokens:\n",
    "            return system_prompt, user_prompt\n",
    "\n",
    "    # Fallback if nothing fits\n",
    "    fallback = \"Transcript:\\n- N/A\"\n",
    "    user_prompt = f\"\"\"Comment: \"{comment}\"\\n{fallback}\\n\\nDoes this comment agree with the transcript?\\n\\nReply ONLY with:\\n1 = agrees\\n-1 = disagrees\\n0 = neutral\"\"\"\n",
    "    return system_prompt, user_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e20ce6-5f9d-4125-a36b-fc7857436739",
   "metadata": {},
   "source": [
    "### Creating the Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "986de4de-c934-4896-b13f-f31f4888af0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GPT-4o Mini batch: 100%|████████████| 56390/56390 [27:03<00:00, 34.74it/s]\n",
      "Saved GPT-4o Mini batch: batch_step_agree_with_transcript.jsonl\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Influenced_Comments.csv\")\n",
    "output_jsonl = \"batch_step_agree_with_transcript.jsonl\"\n",
    "\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating GPT-4o Mini batch\"):\n",
    "        comment_id = str(row[\"Comment_ID\"])\n",
    "        rewritten_comment = row[\"Rewritten Comment\"]\n",
    "        video_id = row[\"Video_ID\"]\n",
    "\n",
    "        # Build token-safe prompt\n",
    "        system_prompt, user_prompt = build_prompt_within_token_limit(rewritten_comment, video_id)\n",
    "\n",
    "        task = {\n",
    "            \"custom_id\": comment_id,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                \"temperature\": 0.0,\n",
    "                \"max_tokens\": 5\n",
    "            }\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "print(f\"Saved GPT-4o Mini batch: {output_jsonl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11da1db-abb9-40c2-9a0d-0d4b81b43abd",
   "metadata": {},
   "source": [
    "### Splitting the Batch due to Token Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b501be17-b89b-4be8-916e-5ad3f8affef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: batch_step_agree_with_transcript.jsonl → 56390 tasks\n",
      "Part 1  : batch_step_agree_with_transcript_part1.jsonl → 28195 tasks\n",
      "Part 2  : batch_step_agree_with_transcript_part2.jsonl → 28195 tasks\n"
     ]
    }
   ],
   "source": [
    "# Input file path\n",
    "input_file = \"batch_step_agree_with_transcript.jsonl\"\n",
    "\n",
    "# Output file names\n",
    "output_file_1 = \"batch_step2_agree_with_transcript_part1.jsonl\"\n",
    "output_file_2 = \"batch_step2_agree_with_transcript_part2.jsonl\"\n",
    "\n",
    "# Read all lines\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Split in half\n",
    "mid = len(lines) // 2\n",
    "part1 = lines[:mid]\n",
    "part2 = lines[mid:]\n",
    "\n",
    "# Write to two files\n",
    "with open(output_file_1, \"w\", encoding=\"utf-8\") as f1:\n",
    "    f1.writelines(part1)\n",
    "\n",
    "with open(output_file_2, \"w\", encoding=\"utf-8\") as f2:\n",
    "    f2.writelines(part2)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Original: {input_file} → {len(lines)} tasks\")\n",
    "print(f\"Part 1  : {output_file_1} → {len(part1)} tasks\")\n",
    "print(f\"Part 2  : {output_file_2} → {len(part2)} tasks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f40e7-f995-4afc-9270-dde5579ffa06",
   "metadata": {},
   "source": [
    "### Submitting Batches to Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "182da5e0-2cc9-4d1b-8dad-e156a167a491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting batch 1/2: batch_step_agree_with_transcript_part1.jsonl\n",
      "Uploaded: File ID = file-JNygyC5BhbXvncj25cEToQ\n",
      "Batch submitted: Batch ID = batch_67e49d84d5008190b5218c58954d381a\n",
      "Waiting 30 minutes before next submission...\n",
      "Submitting batch 2/2: batch_step_agree_with_transcript_part2.jsonl\n",
      "Uploaded: File ID = file-KcPpmUEue2ksS5fQEZ5UZ8\n",
      "Batch submitted: Batch ID = batch_67e4aba177548190bea792e16ed35d64\n"
     ]
    }
   ],
   "source": [
    "# Set your OpenAI API key\n",
    "openai.api_key = \"***************\" \n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# List of batch files to submit\n",
    "batch_files = [\n",
    "    \"batch_step2_agree_with_transcript_part1.jsonl\",\n",
    "    \"batch_step2_agree_with_transcript_part2.jsonl\"\n",
    "]\n",
    "\n",
    "# Submit each batch with 30-minute delay\n",
    "for i, file_path in enumerate(batch_files):\n",
    "    try:\n",
    "        print(f\"Submitting batch {i+1}/{len(batch_files)}: {file_path}\")\n",
    "\n",
    "        # Upload file\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            upload = client.files.create(file=f, purpose=\"batch\")\n",
    "        print(f\"Uploaded: File ID = {upload.id}\")\n",
    "\n",
    "        # Submit batch job\n",
    "        batch = client.batches.create(\n",
    "            input_file_id=upload.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(f\"Batch submitted: Batch ID = {batch.id}\")\n",
    "\n",
    "        # Wait 30 minutes before next submission (if not the last one)\n",
    "        if i < len(batch_files) - 1:\n",
    "            print(\"Waiting 30 minutes before next submission...\")\n",
    "            time.sleep(3600)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to submit {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96f720-ecf4-4f60-bc79-1d09cf8558ca",
   "metadata": {},
   "source": [
    "### Downloading Json Output from Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65011033-858a-4a4d-bc9a-8ea33b3e007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded: file-UjWFGyWcWBXisNh9zzYxBt.jsonl\n",
      "File downloaded: file-TsV6ecRbhBdTukPYpB15Cf.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Set OpenAI API Key\n",
    "openai.api_key = \"****************\"\n",
    "\n",
    "# List of output file IDs from completed batches\n",
    "output_file_ids = [\n",
    "    \"file-UjWFGyWcWBXisNh9zzYxBt\",\n",
    "    \"file-TsV6ecRbhBdTukPYpB15Cf\"\n",
    "]\n",
    "\n",
    "# Download each output file properly\n",
    "for file_id in output_file_ids:\n",
    "    file_response = openai.files.content(file_id)\n",
    "\n",
    "    # Save the file locally in binary mode\n",
    "    output_filename = f\"{file_id}.jsonl\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        for chunk in file_response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "    \n",
    "    print(f\"File downloaded: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fffd3d-e9c4-4afa-9c53-9ef8bfff822d",
   "metadata": {},
   "source": [
    "### Converting Json Output to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60552b67-3225-42f0-bf10-3c963fd43352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file-UjWFGyWcWBXisNh9zzYxBt.jsonl\n",
      "Processing file-TsV6ecRbhBdTukPYpB15Cf.jsonl\n",
      "\n",
      "Extracted responses saved to: agreed_with_transcript_responses.csv\n",
      "Agrees    : 10974\n",
      "Disagrees : 19832\n",
      "Neutral   : 25583\n"
     ]
    }
   ],
   "source": [
    "# List of your JSONL files\n",
    "jsonl_files = [\n",
    "    \"file-UjWFGyWcWBXisNh9zzYxBt.jsonl\",\n",
    "    \"file-TsV6ecRbhBdTukPYpB15Cf.jsonl\"\n",
    "]\n",
    "\n",
    "# Store extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Loop through files\n",
    "for jsonl_file in jsonl_files:\n",
    "    if not os.path.exists(jsonl_file):\n",
    "        print(f\"{jsonl_file} not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {jsonl_file}\")\n",
    "\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            json_obj = json.loads(line)\n",
    "\n",
    "            custom_id = json_obj.get(\"custom_id\", \"\")\n",
    "            response = json_obj.get(\"response\", {}).get(\"body\", {}).get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "            extracted_data.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"Agreed_with_Transcript\": response\n",
    "            })\n",
    "\n",
    "# Create and save CSV\n",
    "df = pd.DataFrame(extracted_data)\n",
    "output_csv = \"agreed_with_transcript_responses.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Summary counts\n",
    "agree = (df[\"Agreed_with_Transcript\"] == \"1\").sum()\n",
    "disagree = (df[\"Agreed_with_Transcript\"] == \"-1\").sum()\n",
    "neutral = (df[\"Agreed_with_Transcript\"] == \"0\").sum()\n",
    "\n",
    "print(f\"\\nExtracted responses saved to: {output_csv}\")\n",
    "print(f\"Agrees    : {agree}\")\n",
    "print(f\"Disagrees : {disagree}\")\n",
    "print(f\"Neutral   : {neutral}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea1e39-8f5a-459e-922b-64af27d03c24",
   "metadata": {},
   "source": [
    "### Merging GPT Agreement Labels into Main Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af177322-18cd-4970-934b-84352de954b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV saved to: Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence.csv\")\n",
    "df_agreed = pd.read_csv(\"agreed_with_transcript_responses.csv\").rename(columns={\"custom_id\": \"Comment_ID\"})\n",
    "\n",
    "df_main[\"Agreed_with_Transcript\"] = pd.merge(\n",
    "    df_main, df_agreed[[\"Comment_ID\", \"Agreed_with_Transcript\"]], on=\"Comment_ID\", how=\"left\"\n",
    ")[\"Agreed_with_Transcript\"].fillna(\"0\")\n",
    "\n",
    "df_main.to_csv(\"Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\", index=False)\n",
    "print(\"New CSV saved to: Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9111a4ea-6221-4d8a-ae1e-de5b601f5717",
   "metadata": {},
   "source": [
    "### Count Claim Detection vs. Transcript Agreement Combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "181f3fbc-fd51-438b-b586-3394f287cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Claim_Detection  Agreed_with_Transcript  Count\n",
      "0                0                      -1  11544\n",
      "1                0                       0  26687\n",
      "2                0                       1   6673\n",
      "3                1                      -1   8288\n",
      "4                1                       0  13947\n",
      "5                1                       1   4301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wkg5hpgj1kl1012mfw_qwby80000gn/T/ipykernel_3039/3803859682.py:4: DtypeWarning: Columns (11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Final_Thesis_Merged.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"Final_Thesis_Merged.csv\")\n",
    "\n",
    "# Remove rows with non-numeric values in 'Agreed_with_Transcript'\n",
    "df = df[pd.to_numeric(df[\"Agreed_with_Transcript\"], errors=\"coerce\").notna()]\n",
    "\n",
    "# Convert both columns to integers\n",
    "df[[\"Claim_Detection\", \"Agreed_with_Transcript\"]] = df[[\"Claim_Detection\", \"Agreed_with_Transcript\"]].astype(int)\n",
    "\n",
    "# Group and count combinations\n",
    "summary = df.groupby([\"Claim_Detection\", \"Agreed_with_Transcript\"]).size().reset_index(name=\"Count\")\n",
    "\n",
    "# Sort for clarity\n",
    "summary = summary.sort_values(by=[\"Claim_Detection\", \"Agreed_with_Transcript\"])\n",
    "\n",
    "# Show result\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759cb46-3142-42a5-80f0-cb0e17288d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
