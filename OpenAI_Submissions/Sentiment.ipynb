{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f82d34-6dba-4b9c-9f6d-4289f47d33ad",
   "metadata": {},
   "source": [
    "# Comment Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebd437-1cf4-4bae-b491-5f3d21f25c23",
   "metadata": {},
   "source": [
    "- In this notebook, I prepared a batch to determine the sentiment of each thesis-relevant comment.  \n",
    "- I used the rewritten comment text to build the batch JSONL file.  \n",
    "- The prompt asked GPT-4o Mini to return `1` for positive sentiment, `-1` for negative sentiment, and `0` for neutral.  \n",
    "- To stay within the token limit, I split the batch into two parts before submitting it to OpenAI’s Batch API.  \n",
    "- Once the outputs were ready, I downloaded the JSONL files and extracted the `custom_id` and sentiment label.  \n",
    "- I saved the results to a CSV to analyse how sentiment varies across countries, events, and comment categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809878f6-278a-401a-b029-79cf48746865",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25305c-a81f-42a7-bb35-8ab756a1d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c98fdcd-9a11-4347-8c80-7d5f9555172e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 71441 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wkg5hpgj1kl1012mfw_qwby80000gn/T/ipykernel_13190/3311419059.py:4: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Loading the full dataset\n",
    "df = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\")\n",
    "print(f\"Loaded {len(df)} comments.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70852e2-9505-4754-9194-0a83fec19e30",
   "metadata": {},
   "source": [
    "### Creating the Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "001ebc6c-c940-4c4d-8a2d-ae03e950555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Sentiment batch: 100%|████████████████████████| 71441/71441 [00:07<00:00, 10006.65it/s]\n",
      "Saved: batch_step_sentiment.jsonl\n"
     ]
    }
   ],
   "source": [
    "output_jsonl = \"batch_step_sentiment.jsonl\"\n",
    "\n",
    "# Opening the file and writing each comment as a separate task\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Sentiment batch\"):\n",
    "        comment_id = str(row[\"Comment_ID\"])\n",
    "        comment = row[\"Rewritten Comment\"]\n",
    "\n",
    "        # Building the request for GPT-4o Mini\n",
    "        task = {\n",
    "            \"custom_id\": comment_id,  \n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are helping a researcher classify YouTube comments by sentiment.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"\"\"Comment: \"{comment}\"\\n\\nHow would you classify the sentiment of this comment?\\n\\nReply ONLY with:\\n1 = positive\\n0 = neutral\\n-1 = negative\"\"\"\n",
    "                    }\n",
    "                ],\n",
    "                \"temperature\": 0,  \n",
    "                \"max_tokens\": 5    \n",
    "            }\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "print(f\"Saved: {output_jsonl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74318123-0aba-41d9-b18e-64ae693ad55a",
   "metadata": {},
   "source": [
    "### Splitting the Batch due to Token Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb871ecc-9f12-4201-898e-0a3a2d17d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 35720 → batch_step_sentiment_part1.jsonl\n",
      "Saved 35721 → batch_step_sentiment_part2.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_file = \"batch_step_sentiment.jsonl\"  # Change to your file\n",
    "output_file_1 = input_file.replace(\".jsonl\", \"_part1.jsonl\")\n",
    "output_file_2 = input_file.replace(\".jsonl\", \"_part2.jsonl\")\n",
    "\n",
    "# Reading the file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Splitting\n",
    "mid = len(lines) // 2\n",
    "part1 = lines[:mid]\n",
    "part2 = lines[mid:]\n",
    "\n",
    "# Write to two new files\n",
    "with open(output_file_1, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(part1)\n",
    "\n",
    "with open(output_file_2, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(part2)\n",
    "\n",
    "# Summary\n",
    "print(f\"Saved {len(part1)} → {output_file_1}\")\n",
    "print(f\"Saved {len(part2)} → {output_file_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d26b4c-ad25-498c-b3a3-7fc49b684420",
   "metadata": {},
   "source": [
    "### Submitting Batches to Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "116d8669-a82b-444d-b824-cbf02001be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting batch 1/2: batch_step_sentiment_part1.jsonl\n",
      "Uploaded: File ID = file–4CrX63HVYgbSBt51wiKAp\n",
      "Batch submitted: Batch ID = batch_67e5d7918d008190b1b713ef161f0942\n",
      "\n",
      "Submitting batch 2/2: batch_step_sentiment_part2.jsonl\n",
      "Uploaded: File ID = file–M9ci2L7xxQTDPVMHAz3hXc\n",
      "Batch submitted: Batch ID = batch_67e5d799d56c819087a6815e1bff479c\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"************\" \n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# JSONL batch files\n",
    "batch_files = [\n",
    "    \"batch_step_sentiment_part1.jsonl\",\n",
    "    \"batch_step_sentiment_part2.jsonl\"\n",
    "]\n",
    "\n",
    "# Submitting batches\n",
    "for i, file_path in enumerate(batch_files):\n",
    "    try:\n",
    "        print(f\"\\nSubmitting batch {i+1}/{len(batch_files)}: {file_path}\")\n",
    "\n",
    "        # Uploading files\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            upload = client.files.create(file=f, purpose=\"batch\")\n",
    "        print(f\"Uploaded: File ID = {upload.id}\")\n",
    "\n",
    "        # Creating batch job\n",
    "        batch = client.batches.create(\n",
    "            input_file_id=upload.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(f\"Batch submitted: Batch ID = {batch.id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to submit {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8628572-bad4-4934-9c7f-e2ee78de7d1c",
   "metadata": {},
   "source": [
    "### Downloading Json Output from Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b1e4e3-69a0-4665-b2ee-a8355958188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded: file-GRo9nijucMzKYLwJ9SeQ5C.jsonl\n",
      "File downloaded: file-SkCuLy5VnbJ5RCKDZfpJXv.jsonl\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"**********\"\n",
    "\n",
    "# List of output file IDs from completed batches\n",
    "output_file_ids = [\n",
    "    \"file-GRo9nijucMzKYLwJ9SeQ5C\",\n",
    "    \"file-SkCuLy5VnbJ5RCKDZfpJXv\"\n",
    "]\n",
    "\n",
    "# Downloading each output file\n",
    "for file_id in output_file_ids:\n",
    "    file_response = openai.files.content(file_id)\n",
    "\n",
    "    # Saving the file locally in binary mode\n",
    "    output_filename = f\"{file_id}.jsonl\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        for chunk in file_response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "    \n",
    "    print(f\"File downloaded: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ca571-cbdd-4e39-b157-70db92f30ef7",
   "metadata": {},
   "source": [
    "### Converting Json Output to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c9d3e0d-35dd-4e56-aaba-4d182ff94078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file-GRo9nijucMzKYLwJ9SeQ5C.jsonl\n",
      "Processing file-SkCuLy5VnbJ5RCKDZfpJXv.jsonl\n",
      "\n",
      "Extracted responses saved to: sentiment_responses.csv\n",
      "Positive : 8765\n",
      "Neutral  : 21092\n",
      "Negative : 41583\n"
     ]
    }
   ],
   "source": [
    "jsonl_files = [\n",
    "    \"file-GRo9nijucMzKYLwJ9SeQ5C.jsonl\",\n",
    "    \"file-SkCuLy5VnbJ5RCKDZfpJXv.jsonl\"\n",
    "]\n",
    "\n",
    "# Storing extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Looping through files\n",
    "for jsonl_file in jsonl_files:\n",
    "    if not os.path.exists(jsonl_file):\n",
    "        print(f\"{jsonl_file} not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {jsonl_file}\")\n",
    "\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            json_obj = json.loads(line)\n",
    "\n",
    "            custom_id = json_obj.get(\"custom_id\", \"\")\n",
    "            response = json_obj.get(\"response\", {}).get(\"body\", {}).get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "            extracted_data.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"Sentiment\": response\n",
    "            })\n",
    "\n",
    "# Creating and saving CSV\n",
    "df = pd.DataFrame(extracted_data)\n",
    "output_csv = \"sentiment_responses.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Summary counts\n",
    "positive = (df[\"Sentiment\"] == \"1\").sum()\n",
    "neutral = (df[\"Sentiment\"] == \"0\").sum()\n",
    "negative = (df[\"Sentiment\"] == \"-1\").sum()\n",
    "\n",
    "print(f\"\\nExtracted responses saved to: {output_csv}\")\n",
    "print(f\"Positive : {positive}\")\n",
    "print(f\"Neutral  : {neutral}\")\n",
    "print(f\"Negative : {negative}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2af49e-5d08-4be9-8053-2d366847e616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
