{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efb026d-a76e-48ea-bf15-724bf9d4efc0",
   "metadata": {},
   "source": [
    "# Fact Or Opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0676755-431d-4be1-b73f-393c19c46f7a",
   "metadata": {},
   "source": [
    "- In this notebook, I prepared a batch to determine whether each thesis-relevant comment expresses a factual statement or a personal opinion.  \n",
    "- I used the rewritten comment text to build the batch JSONL file.  \n",
    "- The prompt asked GPT-4o Mini to return `1` if the comment was factual, or `0` if it was an opinion.  \n",
    "- To stay within the token limit, I split the batch into two parts before submitting it to OpenAI’s Batch API.  \n",
    "- Once the outputs were ready, I downloaded the JSONL files and extracted the `custom_id` and the fact/opinion label.  \n",
    "- I saved the results to a CSV to explore how fact-based and opinion-based comments varied across countries, events, and categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95434db0-7e7c-4f21-9ddf-f527e5811a84",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be85f36-f419-40ee-b3ed-76fdebd480d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b5470c-3379-46f9-9128-007d3a1fc61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 71441 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wkg5hpgj1kl1012mfw_qwby80000gn/T/ipykernel_13655/3311419059.py:4: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Loading the full dataset\n",
    "df = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\")\n",
    "print(f\"Loaded {len(df)} comments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6459b95-a000-4bba-b73f-9923733ff5d1",
   "metadata": {},
   "source": [
    "### Creating the Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ee2fc7-6050-4490-9343-1206cdfa4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Factual/Opinion batch: 100% |█████| 71441/71441 [00:07<00:00, 9540.05it/s]\n",
      "Saved: batch_step_factual_opinion.jsonl\n"
     ]
    }
   ],
   "source": [
    "output_jsonl = \"batch_step_factual_opinion.jsonl\"\n",
    "\n",
    "# Opening the file and writing each comment as a separate task\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Factual/Opinion batch\"):\n",
    "        comment_id = str(row[\"Comment_ID\"])\n",
    "        comment = row[\"Rewritten Comment\"]\n",
    "\n",
    "        # Building the request for GPT-4o Mini\n",
    "        task = {\n",
    "            \"custom_id\": comment_id,  \n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are helping a researcher decide whether a comment is stating a fact or expressing an opinion.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"\"\"Comment: \"{comment}\"\\n\\nDoes this comment state a fact or express an opinion?\\n\\nReply ONLY with:\\n1 = factual\\n0 = opinion\"\"\"\n",
    "                    }\n",
    "                ],\n",
    "                \"temperature\": 0,  \n",
    "                \"max_tokens\": 5    \n",
    "            }\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "print(f\"Saved: {output_jsonl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3e53f-f2f6-4c46-873a-7190a45a53d0",
   "metadata": {},
   "source": [
    "### Splitting the Batch due to Token Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47919e91-689a-4451-b18d-c69930dfb8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 35720 → batch_step_factual_opinion_part1.jsonl\n",
      "Saved 35721 → batch_step_factual_opinion_part2.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_file = \"batch_step_factual_opinion.jsonl\"  \n",
    "output_file_1 = input_file.replace(\".jsonl\", \"_part1.jsonl\")\n",
    "output_file_2 = input_file.replace(\".jsonl\", \"_part2.jsonl\")\n",
    "\n",
    "# Reading the file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Splitting\n",
    "mid = len(lines) // 2\n",
    "part1 = lines[:mid]\n",
    "part2 = lines[mid:]\n",
    "\n",
    "# Writing to two new files\n",
    "with open(output_file_1, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(part1)\n",
    "\n",
    "with open(output_file_2, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(part2)\n",
    "\n",
    "print(f\"Saved {len(part1)} → {output_file_1}\")\n",
    "print(f\"Saved {len(part2)} → {output_file_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b490f8-3cea-49a7-9c78-16fc9952f2d5",
   "metadata": {},
   "source": [
    "### Submitting Batches to Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e19c3a25-f196-441c-a7d3-c1e20f714178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting batch 1/2: batch_step_factual_opinion_part1.jsonl\n",
      "Uploaded: File ID = file-9FEwxceiWTW895qVphkfgg\n",
      "Batch submitted: Batch ID = batch_67e5e08d68dc819090955efe8d849f47\n",
      "\n",
      "Submitting batch 2/2: batch_step_factual_opinion_part2.jsonl\n",
      "Uploaded: File ID = file-9MMyyk9fEk3Ba2fjtUNZn1\n",
      "Batch submitted: Batch ID = batch_67e5e0954308190b38a9a00c72cc9960\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"***************\" \n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# JSONL batch files\n",
    "batch_files = [\n",
    "    \"batch_step_factual_opinion_part1.jsonl\",\n",
    "    \"batch_step_factual_opinion_part2.jsonl\"\n",
    "]\n",
    "\n",
    "# Submitting batches\n",
    "for i, file_path in enumerate(batch_files):\n",
    "    try:\n",
    "        print(f\"\\nSubmitting batch {i+1}/{len(batch_files)}: {file_path}\")\n",
    "\n",
    "        # Uploading file\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            upload = client.files.create(file=f, purpose=\"batch\")\n",
    "        print(f\"Uploaded: File ID = {upload.id}\")\n",
    "\n",
    "        # Creating batch job\n",
    "        batch = client.batches.create(\n",
    "            input_file_id=upload.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(f\"Batch submitted: Batch ID = {batch.id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to submit {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030d81a-d380-42fb-8505-c57866ede5d6",
   "metadata": {},
   "source": [
    "### Downloading Json Output from Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ad1dcd3-8354-4cb4-9a33-648fc3dd55fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded: file-WUVymZPnxciE6JhhTzrFuF.jsonl\n",
      "File downloaded: file-6z3wqTh4SS9jQ59hBeBV1C.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Set OpenAI API Key\n",
    "openai.api_key = \"**************\" \n",
    "\n",
    "# List of output file IDs from completed batches\n",
    "output_file_ids = [\n",
    "    \"file-WUVymZPnxciE6JhhTzrFuF\",\n",
    "    \"file-6z3wqTh4SS9jQ59hBeBV1C\"\n",
    "]\n",
    "\n",
    "# Downloading each output file properly\n",
    "for file_id in output_file_ids:\n",
    "    file_response = openai.files.content(file_id)\n",
    "\n",
    "    # Saving the file locally in binary mode\n",
    "    output_filename = f\"{file_id}.jsonl\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        for chunk in file_response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "    \n",
    "    print(f\"File downloaded: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192144b4-af9f-4738-9891-a5f09cf11070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file-WUVymZPnxciE6JhhTzrFuF.jsonl\n",
      "Processing file-6z3wqTh4SS9jQ59hBeBV1C.jsonl\n",
      "\n",
      "Extracted responses saved to: factual_or_opinion_responses.csv\n",
      "Factual : 3763\n",
      "Opinion : 67678\n"
     ]
    }
   ],
   "source": [
    "# List of JSONL files for Factual/Opinion\n",
    "jsonl_files = [\n",
    "    \"file-WUVymZPnxciE6JhhTzrFuF.jsonl\",\n",
    "    \"file-6z3wqTh4SS9jQ59hBeBV1C.jsonl\"\n",
    "]\n",
    "\n",
    "# Storing extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Looping through files\n",
    "for jsonl_file in jsonl_files:\n",
    "    if not os.path.exists(jsonl_file):\n",
    "        print(f\"{jsonl_file} not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {jsonl_file}\")\n",
    "\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            json_obj = json.loads(line)\n",
    "\n",
    "            custom_id = json_obj.get(\"custom_id\", \"\")\n",
    "            response = json_obj.get(\"response\", {}).get(\"body\", {}).get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "            extracted_data.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"Factual_or_Opinion\": response\n",
    "            })\n",
    "\n",
    "# Creating and save CSV\n",
    "df = pd.DataFrame(extracted_data)\n",
    "output_csv = \"factual_or_opinion_responses.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Summary counts\n",
    "factual = (df[\"Factual_or_Opinion\"] == \"1\").sum()\n",
    "opinion = (df[\"Factual_or_Opinion\"] == \"0\").sum()\n",
    "\n",
    "print(f\"\\nExtracted responses saved to: {output_csv}\")\n",
    "print(f\"Factual : {factual}\")\n",
    "print(f\"Opinion : {opinion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824940bb-e06a-44c1-b1d5-93aa7bf8871f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
