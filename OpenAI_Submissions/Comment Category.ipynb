{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c01958-5d28-4660-b11a-485674a883f8",
   "metadata": {},
   "source": [
    "# Comment Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936671f-3452-4fbd-88da-bc0ba32618e8",
   "metadata": {},
   "source": [
    "- In this notebook, I prepared a batch to classify each thesis-relevant comment into one or more thematic categories.  \n",
    "- I used the rewritten comment text to build the batch JSONL file.  \n",
    "- The prompt asked GPT-4o to assign one or more relevant category labels (e.g., Sportswashing, Human Rights, Financial Ethics, Corruption, etc.).  \n",
    "- Due to the token limit, I split the batch into two parts before submitting it to OpenAI’s Batch API.  \n",
    "- Once the outputs were ready, I downloaded the JSONL files and extracted the `custom_id` and assigned categories.  \n",
    "- I saved the results to a CSV for further analysis, allowing me to see which themes were most commonly associated with the comments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2f6d8-f39f-4563-84a5-44fdfbe0f84d",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215859b-ec1d-44d9-86c1-8d26ca2957b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b0eecd-97b2-4987-98db-051680ea412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 71441 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wkg5hpgj1kl1012mfw_qwby80000gn/T/ipykernel_13070/3311419059.py:4: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Loading the full dataset\n",
    "df = pd.read_csv(\"Thesis_Relevant_With_Transcript_Influence_and_Agreement.csv\")\n",
    "print(f\"Loaded {len(df)} comments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860198a-640c-451e-ad8f-13ad695f14d6",
   "metadata": {},
   "source": [
    "### Creating the Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e41fb09-8f74-4078-80ec-50ef32a738d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Category batch: 100%|████████████████████████| 71441/71441 [00:07<00:00, 9702.39it/s]\n",
      "Saved: batch_step_category.jsonl\n"
     ]
    }
   ],
   "source": [
    "output_jsonl = \"batch_step_category.jsonl\"\n",
    "\n",
    "# Opening the file and writing each row as a separate task\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Category batch\"):\n",
    "        comment_id = str(row[\"Comment_ID\"])\n",
    "        comment = row[\"Rewritten Comment\"]\n",
    "\n",
    "        # Building the request for GPT-4o Mini\n",
    "        task = {\n",
    "            \"custom_id\": comment_id,  \n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are helping a researcher label YouTube comments based on content themes.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"\"\"Comment: \"{comment}\"\\n\\nWhat category does this comment fall under?\\n\\nReply ONLY with one label:\\n- Sportswashing\\n- Human Rights\\n- Financial Ethics\\n- Corruption\\n- Geopolitics\\n- Media Criticism\\n- Other\"\"\"\n",
    "                    }\n",
    "                ],\n",
    "                \"temperature\": 0,        \n",
    "                \"max_tokens\": 10         \n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "        f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "print(f\" Saved: {output_jsonl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843aba4-63ea-4644-8b6d-24cf128e6940",
   "metadata": {},
   "source": [
    "### Splitting the Batch due to Token Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97668c25-b8c2-441d-8600-47dee23bf1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 35720 → batch_step_category_part1.jsonl\n",
      "Saved 35721 → batch_step_category_part2.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_file = \"batch_step_category.jsonl\"  # Change to your file\n",
    "output_file_1 = input_file.replace(\".jsonl\", \"_part1.jsonl\")\n",
    "output_file_2 = input_file.replace(\".jsonl\", \"_part2.jsonl\")\n",
    "\n",
    "# Reading the file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Splitting\n",
    "mid = len(lines) // 2\n",
    "part1 = lines[:mid]\n",
    "part2 = lines[mid:]\n",
    "\n",
    "# Writing to two new files\n",
    "with open(output_file_1, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(part1)\n",
    "\n",
    "with open(output_file_2, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(part2)\n",
    "\n",
    "print(f\"Saved {len(part1)} → {output_file_1}\")\n",
    "print(f\"Saved {len(part2)} → {output_file_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d1a18-94f4-4986-868d-bdb60e27eef2",
   "metadata": {},
   "source": [
    "### Submitting Batches to Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6e48a8-cd37-4409-b669-9d5b8ed264a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting batch 1/2: batch_step_category_part1.jsonl\n",
      "Uploaded: File ID = file-1tDvgdUQiVD8C8huVsQMKK\n",
      "Batch submitted: Batch ID = batch_67e5d1a9f8188190b0964f2a67ee6dce\n",
      "Submitting batch 2/2: batch_step_category_part2.jsonl\n",
      "Uploaded: File ID = file-SfF2bUr2XwLNLdjPWie1rg\n",
      "Batch submitted: Batch ID = batch_67e5d1b3508081908414d40cb6ee3e24\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"***********\"\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "batch_files = [\n",
    "    \"batch_step_category_part1.jsonl\",\n",
    "    \"batch_step_category_part2.jsonl\"\n",
    "]\n",
    "\n",
    "# Submitting batches\n",
    "for i, file_path in enumerate(batch_files):\n",
    "    try:\n",
    "        print(f\"\\nSubmitting batch {i+1}/{len(batch_files)}: {file_path}\")\n",
    "\n",
    "        # Uploading file\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            upload = client.files.create(file=f, purpose=\"batch\")\n",
    "        print(f\" Uploaded: File ID = {upload.id}\")\n",
    "\n",
    "        # Creating batch job\n",
    "        batch = client.batches.create(\n",
    "            input_file_id=upload.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(f\"Batch submitted: Batch ID = {batch.id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to submit {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719cdc3-b5d7-43cc-8a73-c77d82791dd6",
   "metadata": {},
   "source": [
    "### Downloading Json Output from Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0daa1490-7904-47c7-ad0c-db90448ff50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded: file-8xjkdD9kzDg42E8TonAQj5.jsonl\n",
      "File downloaded: file-Sk7PUnXQRgqtotqVpVsHX3.jsonl\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"*****************\" \n",
    "\n",
    "# List of output file IDs from completed batches\n",
    "output_file_ids = [\n",
    "    \"file-8xjkdD9kzDg42E8TonAQj5\",\n",
    "    \"file-Sk7PUnXQRgqtotqVpVsHX3\"\n",
    "]\n",
    "\n",
    "# Downloading each output file properly\n",
    "for file_id in output_file_ids:\n",
    "    file_response = openai.files.content(file_id)\n",
    "\n",
    "    # Saving the file locally in binary mode\n",
    "    output_filename = f\"{file_id}.jsonl\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        for chunk in file_response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "    \n",
    "    print(f\"File downloaded: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb439c6-195b-42c0-9b82-5510249c5588",
   "metadata": {},
   "source": [
    "### Converting Json Output to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4f42864-40d4-484a-a822-c0d3aef955ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file-8xjkdD9kzDg42E8TonAQj5.jsonl\n",
      "Processing file-Sk7PUnXQRgqtotqVpVsHX3.jsonl\n",
      "\n",
      "Extracted responses saved to: category_responses.csv\n",
      "Category breakdown:\n",
      "Category\n",
      "Geopolitics               17605\n",
      "Human Rights              16978\n",
      "Other                     15450\n",
      "Financial Ethics           8598\n",
      "Media Criticism            5665\n",
      "Corruption                 5016\n",
      "Sportswashing              2128\n",
      "Environmental Concerns        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "jsonl_files = [\n",
    "    \"file-8xjkdD9kzDg42E8TonAQj5.jsonl\",\n",
    "    \"file-Sk7PUnXQRgqtotqVpVsHX3.jsonl\"\n",
    "]\n",
    "\n",
    "# Storing extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Looping through files\n",
    "for jsonl_file in jsonl_files:\n",
    "    if not os.path.exists(jsonl_file):\n",
    "        print(f\"{jsonl_file} not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {jsonl_file}\")\n",
    "\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            json_obj = json.loads(line)\n",
    "\n",
    "            custom_id = json_obj.get(\"custom_id\", \"\")\n",
    "            response = json_obj.get(\"response\", {}).get(\"body\", {}).get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "            extracted_data.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"Category\": response\n",
    "            })\n",
    "\n",
    "# Creating and saving CSV\n",
    "df = pd.DataFrame(extracted_data)\n",
    "output_csv = \"category_responses.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"\\nExtracted responses saved to: {output_csv}\")\n",
    "print(\"Category breakdown:\")\n",
    "print(df[\"Category\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8b0be-cf82-45ce-9fea-fb737a473953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
