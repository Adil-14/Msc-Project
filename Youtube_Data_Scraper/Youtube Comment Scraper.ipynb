{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840ef095-02ea-4cb4-baa6-d282db99f60a",
   "metadata": {},
   "source": [
    "## -- YouTube Comment Scraper -- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd3202-7c1c-4d3d-8b18-ec997060bd2b",
   "metadata": {},
   "source": [
    "## Qatar 2022 World Cup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2ad5e-7213-409e-bbb5-d5b54c014656",
   "metadata": {},
   "source": [
    "This section collects public YouTube comments related to the **FIFA World Cup Qatar 2022**.  \n",
    "It uses the YouTube Data API to:\n",
    "\n",
    "- Fetch video metadata (title, category, channel)\n",
    "- Extract top-level comments and engagement info (likes, replies)\n",
    "- Save all output into a structured `.csv` file for later processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75f94dd-c4b9-49c7-9e98-4f8766ebc6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: RVnQnCcVtek...\n",
      "Fetching comments for video: RVnQnCcVtek...\n",
      "✅ 68 comments fetched so far for RVnQnCcVtek\n",
      "Fetching metadata for video: AwTaNr5DsfA...\n",
      "Fetching comments for video: AwTaNr5DsfA...\n",
      "✅ 100 comments fetched so far for AwTaNr5DsfA\n",
      "✅ 200 comments fetched so far for AwTaNr5DsfA\n",
      "✅ 300 comments fetched so far for AwTaNr5DsfA\n",
      "Fetching metadata for video: Gczo2oc14oY...\n",
      "Fetching comments for video: Gczo2oc14oY...\n",
      "✅ 70 comments fetched so far for Gczo2oc14oY\n",
      "Fetching metadata for video: BlKVfJg4hHE...\n",
      "Fetching comments for video: BlKVfJg4hHE...\n",
      "✅ 100 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 200 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 300 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 400 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 500 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 600 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 700 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 800 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 900 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1000 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1100 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1200 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1300 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1400 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1500 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1600 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1700 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1800 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 1900 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2000 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2100 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2200 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2300 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2400 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2500 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2600 comments fetched so far for BlKVfJg4hHE\n",
      "✅ 2676 comments fetched so far for BlKVfJg4hHE\n",
      "Fetching metadata for video: C-0CebFpF_s...\n",
      "Fetching comments for video: C-0CebFpF_s...\n",
      "✅ 100 comments fetched so far for C-0CebFpF_s\n",
      "✅ 200 comments fetched so far for C-0CebFpF_s\n",
      "✅ 300 comments fetched so far for C-0CebFpF_s\n",
      "✅ 400 comments fetched so far for C-0CebFpF_s\n",
      "✅ 500 comments fetched so far for C-0CebFpF_s\n",
      "✅ 600 comments fetched so far for C-0CebFpF_s\n",
      "✅ 700 comments fetched so far for C-0CebFpF_s\n",
      "✅ 800 comments fetched so far for C-0CebFpF_s\n",
      "✅ 900 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1000 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1100 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1200 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1300 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1400 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1500 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1600 comments fetched so far for C-0CebFpF_s\n",
      "✅ 1651 comments fetched so far for C-0CebFpF_s\n",
      "Fetching metadata for video: ynVikeFUvW8...\n",
      "Fetching comments for video: ynVikeFUvW8...\n",
      "✅ 100 comments fetched so far for ynVikeFUvW8\n",
      "✅ 200 comments fetched so far for ynVikeFUvW8\n",
      "✅ 300 comments fetched so far for ynVikeFUvW8\n",
      "✅ 400 comments fetched so far for ynVikeFUvW8\n",
      "✅ 500 comments fetched so far for ynVikeFUvW8\n",
      "✅ 600 comments fetched so far for ynVikeFUvW8\n",
      "✅ 700 comments fetched so far for ynVikeFUvW8\n",
      "✅ 800 comments fetched so far for ynVikeFUvW8\n",
      "✅ 900 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1000 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1100 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1200 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1300 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1400 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1500 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1600 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1700 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1800 comments fetched so far for ynVikeFUvW8\n",
      "✅ 1900 comments fetched so far for ynVikeFUvW8\n",
      "✅ 2000 comments fetched so far for ynVikeFUvW8\n",
      "✅ 2100 comments fetched so far for ynVikeFUvW8\n",
      "✅ 2200 comments fetched so far for ynVikeFUvW8\n",
      "✅ 2300 comments fetched so far for ynVikeFUvW8\n",
      "✅ 2337 comments fetched so far for ynVikeFUvW8\n",
      "Fetching metadata for video: dt_Q03HNbTk...\n",
      "Fetching comments for video: dt_Q03HNbTk...\n",
      "✅ 100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 1900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 2900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 3900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 4900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 5900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 6900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 7900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 8900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 9900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10000 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10100 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10200 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10300 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10400 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10500 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10600 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10700 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10800 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10900 comments fetched so far for dt_Q03HNbTk\n",
      "✅ 10903 comments fetched so far for dt_Q03HNbTk\n",
      "Fetching metadata for video: UMqLDhl8PXw...\n",
      "Fetching comments for video: UMqLDhl8PXw...\n",
      "✅ 100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 1900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 2900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 3900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 4900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 5900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 6900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 7900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 8900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 9900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10400 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10500 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10600 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10700 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10800 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 10900 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 11000 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 11100 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 11200 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 11300 comments fetched so far for UMqLDhl8PXw\n",
      "✅ 11369 comments fetched so far for UMqLDhl8PXw\n",
      "Fetching metadata for video: pesRWBLk5Gs...\n",
      "Fetching comments for video: pesRWBLk5Gs...\n",
      "✅ 100 comments fetched so far for pesRWBLk5Gs\n",
      "✅ 200 comments fetched so far for pesRWBLk5Gs\n",
      "✅ 300 comments fetched so far for pesRWBLk5Gs\n",
      "✅ 400 comments fetched so far for pesRWBLk5Gs\n",
      "✅ 420 comments fetched so far for pesRWBLk5Gs\n",
      "Fetching metadata for video: pgqjGoO1PrQ...\n",
      "Fetching comments for video: pgqjGoO1PrQ...\n",
      "✅ 100 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 200 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 300 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 400 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 500 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 600 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 700 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 800 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 900 comments fetched so far for pgqjGoO1PrQ\n",
      "✅ 947 comments fetched so far for pgqjGoO1PrQ\n",
      "Fetching metadata for video: 4fOGEGmW6kI...\n",
      "Fetching comments for video: 4fOGEGmW6kI...\n",
      "✅ 6 comments fetched so far for 4fOGEGmW6kI\n",
      "Fetching metadata for video: dECVkNBVlqw...\n",
      "Fetching comments for video: dECVkNBVlqw...\n",
      "✅ 100 comments fetched so far for dECVkNBVlqw\n",
      "✅ 200 comments fetched so far for dECVkNBVlqw\n",
      "✅ 278 comments fetched so far for dECVkNBVlqw\n",
      "Fetching metadata for video: vxXfK2-2tyc...\n",
      "Fetching comments for video: vxXfK2-2tyc...\n",
      "✅ 5 comments fetched so far for vxXfK2-2tyc\n",
      "Fetching metadata for video: XE-IoVirk7A...\n",
      "Fetching comments for video: XE-IoVirk7A...\n",
      "✅ 100 comments fetched so far for XE-IoVirk7A\n",
      "✅ 200 comments fetched so far for XE-IoVirk7A\n",
      "✅ 300 comments fetched so far for XE-IoVirk7A\n",
      "✅ 400 comments fetched so far for XE-IoVirk7A\n",
      "✅ 500 comments fetched so far for XE-IoVirk7A\n",
      "✅ 600 comments fetched so far for XE-IoVirk7A\n",
      "✅ 700 comments fetched so far for XE-IoVirk7A\n",
      "✅ 800 comments fetched so far for XE-IoVirk7A\n",
      "✅ 900 comments fetched so far for XE-IoVirk7A\n",
      "✅ 1000 comments fetched so far for XE-IoVirk7A\n",
      "✅ 1100 comments fetched so far for XE-IoVirk7A\n",
      "✅ 1136 comments fetched so far for XE-IoVirk7A\n",
      "Fetching metadata for video: gHjbay54F4U...\n",
      "Fetching comments for video: gHjbay54F4U...\n",
      "✅ 100 comments fetched so far for gHjbay54F4U\n",
      "✅ 200 comments fetched so far for gHjbay54F4U\n",
      "✅ 300 comments fetched so far for gHjbay54F4U\n",
      "✅ 400 comments fetched so far for gHjbay54F4U\n",
      "✅ 500 comments fetched so far for gHjbay54F4U\n",
      "✅ 600 comments fetched so far for gHjbay54F4U\n",
      "✅ 700 comments fetched so far for gHjbay54F4U\n",
      "✅ 800 comments fetched so far for gHjbay54F4U\n",
      "✅ 900 comments fetched so far for gHjbay54F4U\n",
      "✅ 1000 comments fetched so far for gHjbay54F4U\n",
      "✅ 1100 comments fetched so far for gHjbay54F4U\n",
      "✅ 1200 comments fetched so far for gHjbay54F4U\n",
      "✅ 1300 comments fetched so far for gHjbay54F4U\n",
      "✅ 1400 comments fetched so far for gHjbay54F4U\n",
      "✅ 1500 comments fetched so far for gHjbay54F4U\n",
      "✅ 1600 comments fetched so far for gHjbay54F4U\n",
      "✅ 1700 comments fetched so far for gHjbay54F4U\n",
      "✅ 1800 comments fetched so far for gHjbay54F4U\n",
      "✅ 1900 comments fetched so far for gHjbay54F4U\n",
      "✅ 2000 comments fetched so far for gHjbay54F4U\n",
      "✅ 2100 comments fetched so far for gHjbay54F4U\n",
      "✅ 2200 comments fetched so far for gHjbay54F4U\n",
      "✅ 2300 comments fetched so far for gHjbay54F4U\n",
      "✅ 2400 comments fetched so far for gHjbay54F4U\n",
      "✅ 2500 comments fetched so far for gHjbay54F4U\n",
      "✅ 2600 comments fetched so far for gHjbay54F4U\n",
      "✅ 2700 comments fetched so far for gHjbay54F4U\n",
      "✅ 2800 comments fetched so far for gHjbay54F4U\n",
      "✅ 2900 comments fetched so far for gHjbay54F4U\n",
      "✅ 3000 comments fetched so far for gHjbay54F4U\n",
      "✅ 3100 comments fetched so far for gHjbay54F4U\n",
      "✅ 3200 comments fetched so far for gHjbay54F4U\n",
      "✅ 3300 comments fetched so far for gHjbay54F4U\n",
      "✅ 3400 comments fetched so far for gHjbay54F4U\n",
      "✅ 3500 comments fetched so far for gHjbay54F4U\n",
      "✅ 3600 comments fetched so far for gHjbay54F4U\n",
      "✅ 3700 comments fetched so far for gHjbay54F4U\n",
      "✅ 3800 comments fetched so far for gHjbay54F4U\n",
      "✅ 3900 comments fetched so far for gHjbay54F4U\n",
      "✅ 4000 comments fetched so far for gHjbay54F4U\n",
      "✅ 4100 comments fetched so far for gHjbay54F4U\n",
      "✅ 4200 comments fetched so far for gHjbay54F4U\n",
      "✅ 4300 comments fetched so far for gHjbay54F4U\n",
      "✅ 4400 comments fetched so far for gHjbay54F4U\n",
      "✅ 4500 comments fetched so far for gHjbay54F4U\n",
      "✅ 4600 comments fetched so far for gHjbay54F4U\n",
      "✅ 4700 comments fetched so far for gHjbay54F4U\n",
      "✅ 4800 comments fetched so far for gHjbay54F4U\n",
      "✅ 4900 comments fetched so far for gHjbay54F4U\n",
      "✅ 5000 comments fetched so far for gHjbay54F4U\n",
      "✅ 5100 comments fetched so far for gHjbay54F4U\n",
      "✅ 5200 comments fetched so far for gHjbay54F4U\n",
      "✅ 5300 comments fetched so far for gHjbay54F4U\n",
      "✅ 5400 comments fetched so far for gHjbay54F4U\n",
      "✅ 5500 comments fetched so far for gHjbay54F4U\n",
      "✅ 5600 comments fetched so far for gHjbay54F4U\n",
      "✅ 5700 comments fetched so far for gHjbay54F4U\n",
      "✅ 5800 comments fetched so far for gHjbay54F4U\n",
      "✅ 5900 comments fetched so far for gHjbay54F4U\n",
      "✅ 6000 comments fetched so far for gHjbay54F4U\n",
      "✅ 6100 comments fetched so far for gHjbay54F4U\n",
      "✅ 6200 comments fetched so far for gHjbay54F4U\n",
      "✅ 6300 comments fetched so far for gHjbay54F4U\n",
      "✅ 6400 comments fetched so far for gHjbay54F4U\n",
      "✅ 6500 comments fetched so far for gHjbay54F4U\n",
      "✅ 6600 comments fetched so far for gHjbay54F4U\n",
      "✅ 6700 comments fetched so far for gHjbay54F4U\n",
      "✅ 6800 comments fetched so far for gHjbay54F4U\n",
      "✅ 6900 comments fetched so far for gHjbay54F4U\n",
      "✅ 7000 comments fetched so far for gHjbay54F4U\n",
      "✅ 7100 comments fetched so far for gHjbay54F4U\n",
      "✅ 7200 comments fetched so far for gHjbay54F4U\n",
      "✅ 7300 comments fetched so far for gHjbay54F4U\n",
      "✅ 7400 comments fetched so far for gHjbay54F4U\n",
      "✅ 7500 comments fetched so far for gHjbay54F4U\n",
      "✅ 7600 comments fetched so far for gHjbay54F4U\n",
      "✅ 7700 comments fetched so far for gHjbay54F4U\n",
      "✅ 7800 comments fetched so far for gHjbay54F4U\n",
      "✅ 7900 comments fetched so far for gHjbay54F4U\n",
      "✅ 8000 comments fetched so far for gHjbay54F4U\n",
      "✅ 8100 comments fetched so far for gHjbay54F4U\n",
      "✅ 8200 comments fetched so far for gHjbay54F4U\n",
      "✅ 8300 comments fetched so far for gHjbay54F4U\n",
      "✅ 8400 comments fetched so far for gHjbay54F4U\n",
      "✅ 8500 comments fetched so far for gHjbay54F4U\n",
      "✅ 8600 comments fetched so far for gHjbay54F4U\n",
      "✅ 8700 comments fetched so far for gHjbay54F4U\n",
      "✅ 8750 comments fetched so far for gHjbay54F4U\n",
      "Fetching metadata for video: cmWh40u4tqc...\n",
      "Fetching comments for video: cmWh40u4tqc...\n",
      "✅ 100 comments fetched so far for cmWh40u4tqc\n",
      "✅ 200 comments fetched so far for cmWh40u4tqc\n",
      "✅ 300 comments fetched so far for cmWh40u4tqc\n",
      "✅ 400 comments fetched so far for cmWh40u4tqc\n",
      "✅ 500 comments fetched so far for cmWh40u4tqc\n",
      "✅ 600 comments fetched so far for cmWh40u4tqc\n",
      "✅ 630 comments fetched so far for cmWh40u4tqc\n",
      "Fetching metadata for video: 8ANHtDlM0Yk...\n",
      "Fetching comments for video: 8ANHtDlM0Yk...\n",
      "✅ 100 comments fetched so far for 8ANHtDlM0Yk\n",
      "✅ 200 comments fetched so far for 8ANHtDlM0Yk\n",
      "✅ 300 comments fetched so far for 8ANHtDlM0Yk\n",
      "✅ 400 comments fetched so far for 8ANHtDlM0Yk\n",
      "✅ 487 comments fetched so far for 8ANHtDlM0Yk\n",
      "Fetching metadata for video: QPaGtOLkUt8...\n",
      "Fetching comments for video: QPaGtOLkUt8...\n",
      "✅ 100 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 200 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 300 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 400 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 500 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 600 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 700 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 800 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 900 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1000 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1100 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1200 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1300 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1400 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1500 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1600 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1700 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1800 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 1900 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2000 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2100 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2200 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2300 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2400 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2500 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2600 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2700 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2800 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 2900 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 3000 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 3100 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 3200 comments fetched so far for QPaGtOLkUt8\n",
      "✅ 3247 comments fetched so far for QPaGtOLkUt8\n",
      "Fetching metadata for video: CDc065zB85I...\n",
      "Fetching comments for video: CDc065zB85I...\n",
      "✅ 100 comments fetched so far for CDc065zB85I\n",
      "✅ 200 comments fetched so far for CDc065zB85I\n",
      "✅ 254 comments fetched so far for CDc065zB85I\n",
      "Fetching metadata for video: Qf8TGA2yOKI...\n",
      "Fetching comments for video: Qf8TGA2yOKI...\n",
      "✅ 100 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 200 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 300 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 400 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 500 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 600 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 700 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 800 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 900 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 1000 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 1100 comments fetched so far for Qf8TGA2yOKI\n",
      "✅ 1143 comments fetched so far for Qf8TGA2yOKI\n",
      "Fetching metadata for video: Mfx-fux7NGE...\n",
      "Fetching comments for video: Mfx-fux7NGE...\n",
      "✅ 100 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 200 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 300 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 400 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 500 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 600 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 700 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 800 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 900 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1000 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1100 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1200 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1300 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1400 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1500 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1600 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1700 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1800 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1900 comments fetched so far for Mfx-fux7NGE\n",
      "✅ 1941 comments fetched so far for Mfx-fux7NGE\n",
      "Fetching metadata for video: I0EsOFDA6uM...\n",
      "Fetching comments for video: I0EsOFDA6uM...\n",
      "✅ 100 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 200 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 300 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 400 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 500 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 600 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 700 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 800 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 900 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1000 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1100 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1200 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1300 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1400 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1500 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1600 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1700 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1800 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 1900 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2000 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2100 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2200 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2300 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2400 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2500 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2600 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2700 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2800 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 2900 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3000 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3100 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3200 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3300 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3400 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3500 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3600 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3700 comments fetched so far for I0EsOFDA6uM\n",
      "✅ 3793 comments fetched so far for I0EsOFDA6uM\n",
      "Fetching metadata for video: qTlG7WyUuLQ...\n",
      "Fetching comments for video: qTlG7WyUuLQ...\n",
      "✅ 100 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 200 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 300 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 400 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 500 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 600 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 700 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 800 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 900 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1000 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1100 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1200 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1300 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1400 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1500 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1600 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1700 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1800 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 1900 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2000 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2100 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2200 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2300 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2400 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2500 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2600 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2700 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2800 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 2900 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 3000 comments fetched so far for qTlG7WyUuLQ\n",
      "✅ 3075 comments fetched so far for qTlG7WyUuLQ\n",
      "Fetching metadata for video: zQG07WqUD10...\n",
      "Fetching comments for video: zQG07WqUD10...\n",
      "✅ 70 comments fetched so far for zQG07WqUD10\n",
      "Fetching metadata for video: xyjnDBoJY7k...\n",
      "Fetching comments for video: xyjnDBoJY7k...\n",
      "✅ 100 comments fetched so far for xyjnDBoJY7k\n",
      "✅ 200 comments fetched so far for xyjnDBoJY7k\n",
      "✅ 300 comments fetched so far for xyjnDBoJY7k\n",
      "✅ 400 comments fetched so far for xyjnDBoJY7k\n",
      "✅ 500 comments fetched so far for xyjnDBoJY7k\n",
      "✅ 600 comments fetched so far for xyjnDBoJY7k\n",
      "✅ 678 comments fetched so far for xyjnDBoJY7k\n",
      "Fetching metadata for video: e61NcyUJbIg...\n",
      "Fetching comments for video: e61NcyUJbIg...\n",
      "✅ 100 comments fetched so far for e61NcyUJbIg\n",
      "✅ 200 comments fetched so far for e61NcyUJbIg\n",
      "✅ 300 comments fetched so far for e61NcyUJbIg\n",
      "✅ 400 comments fetched so far for e61NcyUJbIg\n",
      "✅ 500 comments fetched so far for e61NcyUJbIg\n",
      "✅ 600 comments fetched so far for e61NcyUJbIg\n",
      "✅ 700 comments fetched so far for e61NcyUJbIg\n",
      "✅ 800 comments fetched so far for e61NcyUJbIg\n",
      "✅ 900 comments fetched so far for e61NcyUJbIg\n",
      "✅ 902 comments fetched so far for e61NcyUJbIg\n",
      "Fetching metadata for video: 7KL9LExsPLI...\n",
      "Fetching comments for video: 7KL9LExsPLI...\n",
      "✅ 100 comments fetched so far for 7KL9LExsPLI\n",
      "✅ 200 comments fetched so far for 7KL9LExsPLI\n",
      "✅ 300 comments fetched so far for 7KL9LExsPLI\n",
      "✅ 400 comments fetched so far for 7KL9LExsPLI\n",
      "✅ 500 comments fetched so far for 7KL9LExsPLI\n",
      "✅ 600 comments fetched so far for 7KL9LExsPLI\n",
      "✅ 700 comments fetched so far for 7KL9LExsPLI\n",
      "✅ 763 comments fetched so far for 7KL9LExsPLI\n",
      "Fetching metadata for video: SO23de1XJ7g...\n",
      "Fetching comments for video: SO23de1XJ7g...\n",
      "✅ 65 comments fetched so far for SO23de1XJ7g\n",
      "Fetching metadata for video: Esc-QKITW5k...\n",
      "Fetching comments for video: Esc-QKITW5k...\n",
      "✅ 100 comments fetched so far for Esc-QKITW5k\n",
      "✅ 200 comments fetched so far for Esc-QKITW5k\n",
      "✅ 300 comments fetched so far for Esc-QKITW5k\n",
      "✅ 371 comments fetched so far for Esc-QKITW5k\n",
      "Fetching metadata for video: QLNp5JA3g_A...\n",
      "Fetching comments for video: QLNp5JA3g_A...\n",
      "✅ 92 comments fetched so far for QLNp5JA3g_A\n",
      "Fetching metadata for video: RVvfAOqau8E...\n",
      "Fetching comments for video: RVvfAOqau8E...\n",
      "✅ 100 comments fetched so far for RVvfAOqau8E\n",
      "✅ 200 comments fetched so far for RVvfAOqau8E\n",
      "✅ 222 comments fetched so far for RVvfAOqau8E\n",
      "Fetching metadata for video: U0onvrn71Qc...\n",
      "Fetching comments for video: U0onvrn71Qc...\n",
      "✅ 100 comments fetched so far for U0onvrn71Qc\n",
      "✅ 200 comments fetched so far for U0onvrn71Qc\n",
      "✅ 300 comments fetched so far for U0onvrn71Qc\n",
      "✅ 400 comments fetched so far for U0onvrn71Qc\n",
      "✅ 500 comments fetched so far for U0onvrn71Qc\n",
      "✅ 600 comments fetched so far for U0onvrn71Qc\n",
      "✅ 700 comments fetched so far for U0onvrn71Qc\n",
      "✅ 714 comments fetched so far for U0onvrn71Qc\n",
      "Fetching metadata for video: ejd7Zmz1r64...\n",
      "Fetching comments for video: ejd7Zmz1r64...\n",
      "✅ 100 comments fetched so far for ejd7Zmz1r64\n",
      "✅ 200 comments fetched so far for ejd7Zmz1r64\n",
      "✅ 300 comments fetched so far for ejd7Zmz1r64\n",
      "✅ 400 comments fetched so far for ejd7Zmz1r64\n",
      "✅ 500 comments fetched so far for ejd7Zmz1r64\n",
      "✅ 600 comments fetched so far for ejd7Zmz1r64\n",
      "✅ 700 comments fetched so far for ejd7Zmz1r64\n",
      "✅ 750 comments fetched so far for ejd7Zmz1r64\n",
      "Fetching metadata for video: g5ujVKuWRPI...\n",
      "Fetching comments for video: g5ujVKuWRPI...\n",
      "✅ 100 comments fetched so far for g5ujVKuWRPI\n",
      "✅ 200 comments fetched so far for g5ujVKuWRPI\n",
      "✅ 263 comments fetched so far for g5ujVKuWRPI\n",
      "Fetching metadata for video: c9sXyihOO8Y...\n",
      "Fetching comments for video: c9sXyihOO8Y...\n",
      "✅ 100 comments fetched so far for c9sXyihOO8Y\n",
      "✅ 200 comments fetched so far for c9sXyihOO8Y\n",
      "✅ 300 comments fetched so far for c9sXyihOO8Y\n",
      "✅ 400 comments fetched so far for c9sXyihOO8Y\n",
      "✅ 473 comments fetched so far for c9sXyihOO8Y\n",
      "Fetching metadata for video: kQdrgesj8p8...\n",
      "Fetching comments for video: kQdrgesj8p8...\n",
      "✅ 100 comments fetched so far for kQdrgesj8p8\n",
      "✅ 200 comments fetched so far for kQdrgesj8p8\n",
      "✅ 296 comments fetched so far for kQdrgesj8p8\n",
      "Fetching metadata for video: 0LG-u2RZXPo...\n",
      "Fetching comments for video: 0LG-u2RZXPo...\n",
      "✅ 100 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 200 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 300 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 400 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 500 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 600 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 700 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 800 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 900 comments fetched so far for 0LG-u2RZXPo\n",
      "✅ 937 comments fetched so far for 0LG-u2RZXPo\n",
      "Fetching metadata for video: 9HNRDGlU_-4...\n",
      "Fetching comments for video: 9HNRDGlU_-4...\n",
      "✅ 100 comments fetched so far for 9HNRDGlU_-4\n",
      "✅ 176 comments fetched so far for 9HNRDGlU_-4\n",
      "Fetching metadata for video: RIJC9WzD7tc...\n",
      "Fetching comments for video: RIJC9WzD7tc...\n",
      "✅ 100 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 200 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 300 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 400 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 500 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 600 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 700 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 800 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 900 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 1000 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 1100 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 1200 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 1300 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 1400 comments fetched so far for RIJC9WzD7tc\n",
      "✅ 1451 comments fetched so far for RIJC9WzD7tc\n",
      "Fetching metadata for video: xPta_JXwSc0...\n",
      "Fetching comments for video: xPta_JXwSc0...\n",
      "✅ 100 comments fetched so far for xPta_JXwSc0\n",
      "✅ 124 comments fetched so far for xPta_JXwSc0\n",
      "Fetching metadata for video: 09MPzF03iec...\n",
      "Fetching comments for video: 09MPzF03iec...\n",
      "✅ 100 comments fetched so far for 09MPzF03iec\n",
      "✅ 200 comments fetched so far for 09MPzF03iec\n",
      "✅ 300 comments fetched so far for 09MPzF03iec\n",
      "✅ 393 comments fetched so far for 09MPzF03iec\n",
      "Fetching metadata for video: u7rzezRtkj0...\n",
      "Fetching comments for video: u7rzezRtkj0...\n",
      "✅ 69 comments fetched so far for u7rzezRtkj0\n",
      "Fetching metadata for video: x8Hu3V4XS_o...\n",
      "Fetching comments for video: x8Hu3V4XS_o...\n",
      "✅ 100 comments fetched so far for x8Hu3V4XS_o\n",
      "✅ 200 comments fetched so far for x8Hu3V4XS_o\n",
      "✅ 300 comments fetched so far for x8Hu3V4XS_o\n",
      "✅ 333 comments fetched so far for x8Hu3V4XS_o\n",
      "Fetching metadata for video: UehxGD04Y2U...\n",
      "Fetching comments for video: UehxGD04Y2U...\n",
      "✅ 100 comments fetched so far for UehxGD04Y2U\n",
      "✅ 200 comments fetched so far for UehxGD04Y2U\n",
      "✅ 300 comments fetched so far for UehxGD04Y2U\n",
      "✅ 358 comments fetched so far for UehxGD04Y2U\n",
      "Fetching metadata for video: T7OO1mOk7_g...\n",
      "Fetching comments for video: T7OO1mOk7_g...\n",
      "✅ 100 comments fetched so far for T7OO1mOk7_g\n",
      "✅ 200 comments fetched so far for T7OO1mOk7_g\n",
      "✅ 300 comments fetched so far for T7OO1mOk7_g\n",
      "✅ 301 comments fetched so far for T7OO1mOk7_g\n",
      "Fetching metadata for video: i3qXyUX9320...\n",
      "Fetching comments for video: i3qXyUX9320...\n",
      "✅ 100 comments fetched so far for i3qXyUX9320\n",
      "✅ 200 comments fetched so far for i3qXyUX9320\n",
      "✅ 300 comments fetched so far for i3qXyUX9320\n",
      "✅ 400 comments fetched so far for i3qXyUX9320\n",
      "✅ 413 comments fetched so far for i3qXyUX9320\n",
      "Fetching metadata for video: ITKOCKpEca8...\n",
      "Fetching comments for video: ITKOCKpEca8...\n",
      "✅ 100 comments fetched so far for ITKOCKpEca8\n",
      "✅ 200 comments fetched so far for ITKOCKpEca8\n",
      "✅ 300 comments fetched so far for ITKOCKpEca8\n",
      "✅ 400 comments fetched so far for ITKOCKpEca8\n",
      "✅ 500 comments fetched so far for ITKOCKpEca8\n",
      "✅ 600 comments fetched so far for ITKOCKpEca8\n",
      "✅ 640 comments fetched so far for ITKOCKpEca8\n",
      "Fetching metadata for video: Cr3d4Oi0Mas...\n",
      "Fetching comments for video: Cr3d4Oi0Mas...\n",
      "✅ 100 comments fetched so far for Cr3d4Oi0Mas\n",
      "✅ 200 comments fetched so far for Cr3d4Oi0Mas\n",
      "✅ 300 comments fetched so far for Cr3d4Oi0Mas\n",
      "✅ 400 comments fetched so far for Cr3d4Oi0Mas\n",
      "✅ 473 comments fetched so far for Cr3d4Oi0Mas\n",
      "Fetching metadata for video: H9VQPwPMxz8...\n",
      "Fetching comments for video: H9VQPwPMxz8...\n",
      "✅ 78 comments fetched so far for H9VQPwPMxz8\n",
      "Fetching metadata for video: LhSPzahjZfs...\n",
      "Fetching comments for video: LhSPzahjZfs...\n",
      "✅ 100 comments fetched so far for LhSPzahjZfs\n",
      "✅ 200 comments fetched so far for LhSPzahjZfs\n",
      "✅ 228 comments fetched so far for LhSPzahjZfs\n",
      "Fetching metadata for video: DI8Ksl0Rn64...\n",
      "Fetching comments for video: DI8Ksl0Rn64...\n",
      "✅ 100 comments fetched so far for DI8Ksl0Rn64\n",
      "✅ 200 comments fetched so far for DI8Ksl0Rn64\n",
      "✅ 210 comments fetched so far for DI8Ksl0Rn64\n",
      "Fetching metadata for video: TEVev8tIq0c...\n",
      "Fetching comments for video: TEVev8tIq0c...\n",
      "✅ 100 comments fetched so far for TEVev8tIq0c\n",
      "✅ 200 comments fetched so far for TEVev8tIq0c\n",
      "✅ 300 comments fetched so far for TEVev8tIq0c\n",
      "✅ 333 comments fetched so far for TEVev8tIq0c\n",
      "Fetching metadata for video: u5jTVcx_a7g...\n",
      "Fetching comments for video: u5jTVcx_a7g...\n",
      "✅ 100 comments fetched so far for u5jTVcx_a7g\n",
      "✅ 200 comments fetched so far for u5jTVcx_a7g\n",
      "✅ 277 comments fetched so far for u5jTVcx_a7g\n",
      "\n",
      "✅ Total Comments Retrieved: 67939\n",
      "📂 All data saved to 'FIFA_World_Cup_2022_Qatar.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# YouTube API Key\n",
    "API_KEY = \"******************************\"\n",
    "\n",
    "# List of YouTube video IDs to scrape comments from\n",
    "VIDEO_IDS = [\n",
    "    \"RVnQnCcVtek\", \"AwTaNr5DsfA\", \"Gczo2oc14oY\", \"BlKVfJg4hHE\", \"C-0CebFpF_s\",\n",
    "    \"ynVikeFUvW8\", \"dt_Q03HNbTk\", \"UMqLDhl8PXw\", \"pesRWBLk5Gs\", \"pgqjGoO1PrQ\",\n",
    "    \"4fOGEGmW6kI\", \"dECVkNBVlqw\", \"vxXfK2-2tyc\", \"XE-IoVirk7A\", \"gHjbay54F4U\",\n",
    "    \"cmWh40u4tqc\", \"8ANHtDlM0Yk\", \"QPaGtOLkUt8\", \"CDc065zB85I\", \"Qf8TGA2yOKI\",\n",
    "    \"Mfx-fux7NGE\", \"I0EsOFDA6uM\", \"qTlG7WyUuLQ\", \"zQG07WqUD10\", \"xyjnDBoJY7k\",\n",
    "    \"e61NcyUJbIg\", \"7KL9LExsPLI\", \"SO23de1XJ7g\", \"Esc-QKITW5k\", \"QLNp5JA3g_A\",\n",
    "    \"RVvfAOqau8E\", \"U0onvrn71Qc\", \"ejd7Zmz1r64\", \"g5ujVKuWRPI\", \"c9sXyihOO8Y\",\n",
    "    \"kQdrgesj8p8\", \"0LG-u2RZXPo\", \"9HNRDGlU_-4\", \"RIJC9WzD7tc\", \"xPta_JXwSc0\",\n",
    "    \"09MPzF03iec\", \"u7rzezRtkj0\", \"x8Hu3V4XS_o\", \"UehxGD04Y2U\", \"T7OO1mOk7_g\",\n",
    "    \"i3qXyUX9320\", \"ITKOCKpEca8\", \"Cr3d4Oi0Mas\", \"H9VQPwPMxz8\", \"LhSPzahjZfs\",\n",
    "    \"DI8Ksl0Rn64\", \"TEVev8tIq0c\", \"u5jTVcx_a7g\"\n",
    "]\n",
    "\n",
    "# This pulls YouTube category names using the API, maps them to category IDs\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "# Get full dictionary of category ID → category name\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# Name of the CSV where all comments will be saved\n",
    "OUTPUT_FILE = \"FIFA_World_Cup_2022_Qatar.csv\"\n",
    "\n",
    "# Check if the file already exists so we don’t re-write the header\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Open the CSV file in append mode (add new rows without wiping old ones)\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Only write the header row if file didn’t already exist\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Track how many comments we collect in total\n",
    "\n",
    "    # Loop through every video in the list\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # First get video metadata (title, category ID, channel name)\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                # If video metadata isn’t available, skip to the next video\n",
    "                print(f\" No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            # If the API request fails, skip this video\n",
    "            print(f\" Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Set up the initial API call for comment threads\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0  # Track how many comments we get per video\n",
    "\n",
    "        # Keep fetching pages of comments until there are no more\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "\n",
    "                # Loop through each top-level comment\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    # Write comment info and metadata to the CSV\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "\n",
    "                # If there's a next page, update the URL with the new page token\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                # If comment fetching fails, stop and move on\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            # Pause for a second to avoid hitting the rate limit\n",
    "            time.sleep(1)\n",
    "\n",
    "# Final printout of total comment count and file name\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc2001-1c3e-4091-ae58-8e07c9872fd9",
   "metadata": {},
   "source": [
    "## Newcastle Takeover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e428b13-63c9-4fd4-a89d-06a92ac71ae1",
   "metadata": {},
   "source": [
    "This section collects YouTube comments related to the **Saudi-led takeover of Newcastle United**.  \n",
    "\n",
    "The script performs the following steps:\n",
    "\n",
    "- Retrieves video metadata (title, channel, and category)\n",
    "- Extracts top-level comments using the YouTube Data API\n",
    "- Saves all relevant comment data into a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e881da12-e30c-44d3-a2a1-4e85db7e3560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: X9fdKFfOPck...\n",
      "Fetching comments for video: X9fdKFfOPck...\n",
      "✅ 100 comments fetched so far for X9fdKFfOPck\n",
      "✅ 200 comments fetched so far for X9fdKFfOPck\n",
      "✅ 300 comments fetched so far for X9fdKFfOPck\n",
      "✅ 400 comments fetched so far for X9fdKFfOPck\n",
      "✅ 500 comments fetched so far for X9fdKFfOPck\n",
      "✅ 600 comments fetched so far for X9fdKFfOPck\n",
      "✅ 700 comments fetched so far for X9fdKFfOPck\n",
      "✅ 800 comments fetched so far for X9fdKFfOPck\n",
      "✅ 900 comments fetched so far for X9fdKFfOPck\n",
      "✅ 1000 comments fetched so far for X9fdKFfOPck\n",
      "✅ 1100 comments fetched so far for X9fdKFfOPck\n",
      "✅ 1114 comments fetched so far for X9fdKFfOPck\n",
      "Fetching metadata for video: P_5l7dF6kak...\n",
      "Fetching comments for video: P_5l7dF6kak...\n",
      "✅ 59 comments fetched so far for P_5l7dF6kak\n",
      "Fetching metadata for video: 8JjNY_CCosw...\n",
      "Fetching comments for video: 8JjNY_CCosw...\n",
      "✅ 100 comments fetched so far for 8JjNY_CCosw\n",
      "✅ 200 comments fetched so far for 8JjNY_CCosw\n",
      "✅ 300 comments fetched so far for 8JjNY_CCosw\n",
      "✅ 400 comments fetched so far for 8JjNY_CCosw\n",
      "✅ 500 comments fetched so far for 8JjNY_CCosw\n",
      "✅ 509 comments fetched so far for 8JjNY_CCosw\n",
      "Fetching metadata for video: E8vssyn8kOg...\n",
      "Fetching comments for video: E8vssyn8kOg...\n",
      "✅ 54 comments fetched so far for E8vssyn8kOg\n",
      "Fetching metadata for video: CtNX1QSztYc...\n",
      "Fetching comments for video: CtNX1QSztYc...\n",
      "✅ 62 comments fetched so far for CtNX1QSztYc\n",
      "Fetching metadata for video: I7fUfqM3N2g...\n",
      "Fetching comments for video: I7fUfqM3N2g...\n",
      "✅ 100 comments fetched so far for I7fUfqM3N2g\n",
      "✅ 200 comments fetched so far for I7fUfqM3N2g\n",
      "✅ 272 comments fetched so far for I7fUfqM3N2g\n",
      "Fetching metadata for video: kMI_HucvbUU...\n",
      "Fetching comments for video: kMI_HucvbUU...\n",
      "✅ 100 comments fetched so far for kMI_HucvbUU\n",
      "✅ 200 comments fetched so far for kMI_HucvbUU\n",
      "✅ 300 comments fetched so far for kMI_HucvbUU\n",
      "✅ 360 comments fetched so far for kMI_HucvbUU\n",
      "Fetching metadata for video: y11a2fYjlpQ...\n",
      "Fetching comments for video: y11a2fYjlpQ...\n",
      "✅ 16 comments fetched so far for y11a2fYjlpQ\n",
      "Fetching metadata for video: svMZFJf_DDo...\n",
      "Fetching comments for video: svMZFJf_DDo...\n",
      "✅ 18 comments fetched so far for svMZFJf_DDo\n",
      "Fetching metadata for video: yNx4BXnHNOw...\n",
      "Fetching comments for video: yNx4BXnHNOw...\n",
      "✅ 100 comments fetched so far for yNx4BXnHNOw\n",
      "✅ 200 comments fetched so far for yNx4BXnHNOw\n",
      "✅ 300 comments fetched so far for yNx4BXnHNOw\n",
      "✅ 325 comments fetched so far for yNx4BXnHNOw\n",
      "Fetching metadata for video: CjYJa4ZQsZU...\n",
      "Fetching comments for video: CjYJa4ZQsZU...\n",
      "✅ 100 comments fetched so far for CjYJa4ZQsZU\n",
      "✅ 200 comments fetched so far for CjYJa4ZQsZU\n",
      "✅ 211 comments fetched so far for CjYJa4ZQsZU\n",
      "Fetching metadata for video: r_cSRwCdnsk...\n",
      "Fetching comments for video: r_cSRwCdnsk...\n",
      "✅ 55 comments fetched so far for r_cSRwCdnsk\n",
      "Fetching metadata for video: kS1wVgl1xSw...\n",
      "Fetching comments for video: kS1wVgl1xSw...\n",
      "✅ 54 comments fetched so far for kS1wVgl1xSw\n",
      "Fetching metadata for video: 1c3BSJHffI0...\n",
      "Fetching comments for video: 1c3BSJHffI0...\n",
      "✅ 66 comments fetched so far for 1c3BSJHffI0\n",
      "Fetching metadata for video: crhO6qOxQEI...\n",
      "Fetching comments for video: crhO6qOxQEI...\n",
      "✅ 36 comments fetched so far for crhO6qOxQEI\n",
      "Fetching metadata for video: BYgX4YnLvps...\n",
      "Fetching comments for video: BYgX4YnLvps...\n",
      "✅ 11 comments fetched so far for BYgX4YnLvps\n",
      "Fetching metadata for video: m5pVViOwGAc...\n",
      "Fetching comments for video: m5pVViOwGAc...\n",
      "✅ 100 comments fetched so far for m5pVViOwGAc\n",
      "✅ 200 comments fetched so far for m5pVViOwGAc\n",
      "✅ 240 comments fetched so far for m5pVViOwGAc\n",
      "Fetching metadata for video: BvE_U8KANnI...\n",
      "Fetching comments for video: BvE_U8KANnI...\n",
      "✅ 100 comments fetched so far for BvE_U8KANnI\n",
      "✅ 200 comments fetched so far for BvE_U8KANnI\n",
      "✅ 300 comments fetched so far for BvE_U8KANnI\n",
      "✅ 400 comments fetched so far for BvE_U8KANnI\n",
      "✅ 420 comments fetched so far for BvE_U8KANnI\n",
      "Fetching metadata for video: 56wWl3Uezjg...\n",
      "Fetching comments for video: 56wWl3Uezjg...\n",
      "✅ 100 comments fetched so far for 56wWl3Uezjg\n",
      "✅ 200 comments fetched so far for 56wWl3Uezjg\n",
      "✅ 300 comments fetched so far for 56wWl3Uezjg\n",
      "✅ 400 comments fetched so far for 56wWl3Uezjg\n",
      "✅ 494 comments fetched so far for 56wWl3Uezjg\n",
      "Fetching metadata for video: LiaxgseTd7M...\n",
      "Fetching comments for video: LiaxgseTd7M...\n",
      "✅ 89 comments fetched so far for LiaxgseTd7M\n",
      "Fetching metadata for video: 7BWaCDRzN_Y...\n",
      "Fetching comments for video: 7BWaCDRzN_Y...\n",
      "✅ 100 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 200 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 300 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 400 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 500 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 600 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 700 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 800 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 900 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1000 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1100 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1200 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1300 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1400 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1500 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1600 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1700 comments fetched so far for 7BWaCDRzN_Y\n",
      "✅ 1721 comments fetched so far for 7BWaCDRzN_Y\n",
      "Fetching metadata for video: 7oVTGh-yr-Y...\n",
      "Fetching comments for video: 7oVTGh-yr-Y...\n",
      "✅ 100 comments fetched so far for 7oVTGh-yr-Y\n",
      "✅ 114 comments fetched so far for 7oVTGh-yr-Y\n",
      "Fetching metadata for video: fqWP6Eao8qk...\n",
      "Fetching comments for video: fqWP6Eao8qk...\n",
      "✅ 100 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 200 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 300 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 400 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 500 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 600 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 700 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 800 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 900 comments fetched so far for fqWP6Eao8qk\n",
      "✅ 989 comments fetched so far for fqWP6Eao8qk\n",
      "Fetching metadata for video: Ss3-fVMOwXU...\n",
      "Fetching comments for video: Ss3-fVMOwXU...\n",
      "✅ 100 comments fetched so far for Ss3-fVMOwXU\n",
      "✅ 200 comments fetched so far for Ss3-fVMOwXU\n",
      "✅ 300 comments fetched so far for Ss3-fVMOwXU\n",
      "✅ 307 comments fetched so far for Ss3-fVMOwXU\n",
      "Fetching metadata for video: vLlOEOT3HKM...\n",
      "Fetching comments for video: vLlOEOT3HKM...\n",
      "✅ 96 comments fetched so far for vLlOEOT3HKM\n",
      "\n",
      "✅ Total Comments Retrieved: 7692\n",
      "📂 All data saved to 'Newcastle_Takeover_Saudi_Arabia.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of YouTube video IDs related to the Newcastle United takeover\n",
    "VIDEO_IDS = [\n",
    "    \"X9fdKFfOPck\", \"P_5l7dF6kak\", \"8JjNY_CCosw\", \"E8vssyn8kOg\", \"CtNX1QSztYc\",\n",
    "    \"I7fUfqM3N2g\", \"kMI_HucvbUU\", \"y11a2fYjlpQ\", \"svMZFJf_DDo\", \"yNx4BXnHNOw\",\n",
    "    \"CjYJa4ZQsZU\", \"r_cSRwCdnsk\", \"kS1wVgl1xSw\", \"1c3BSJHffI0\", \"crhO6qOxQEI\",\n",
    "    \"BYgX4YnLvps\", \"m5pVViOwGAc\", \"BvE_U8KANnI\", \"56wWl3Uezjg\", \"LiaxgseTd7M\",\n",
    "    \"7BWaCDRzN_Y\", \"7oVTGh-yr-Y\", \"fqWP6Eao8qk\", \"Ss3-fVMOwXU\", \"vLlOEOT3HKM\"\n",
    "]\n",
    "\n",
    "# Function to get category names based on YouTube's category ID mapping\n",
    "# Helps convert category IDs to readable labels\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "# Build the full mapping to use later\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# Output CSV file that stores all comments + video metadata for this topic\n",
    "OUTPUT_FILE = \"Newcastle_Takeover_Saudi_Arabia.csv\"\n",
    "\n",
    "# Check if this CSV already exists (used to decide whether to write header)\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Open the CSV in append mode so we don't erase old data if rerun\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "# Only write the header row if this is a new file\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Used to keep count of all comments collected\n",
    "\n",
    "# Loop through each video in the list\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "\n",
    "# First: pull video-level metadata\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                # Sometimes the video metadata isn't available — skip that video\n",
    "                print(f\" No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            # API call failed — skip this one\n",
    "            print(f\" Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Starting the request for top-level comments on the video\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0  # Tracking number of comments fetched for this video\n",
    "\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    # Write the comment and video info to the CSV file\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "\n",
    "                # If there's more pages of comments, keep going\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                # API call failed when trying to get comments\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            # Add a pause to avoid hitting API rate limits\n",
    "            time.sleep(1)\n",
    "\n",
    "# Printing the summary once it's all done\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a63a02-460b-4aad-b2c3-d326a28df28d",
   "metadata": {},
   "source": [
    "## All Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16432b24-1925-489d-8b33-b1934a8b9ab2",
   "metadata": {},
   "source": [
    "This section collects public YouTube comments from videos that cover **multiple major sportswashing events** together.  \n",
    "It uses the YouTube Data API to:\n",
    "\n",
    "- Fetch video metadata (title, category, channel)\n",
    "- Extract top-level comments and engagement info (likes, replies)\n",
    "- Save all output into a structured `.csv` file for later processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d1a5e9f-c73e-4364-afb6-311526ea0c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: OMTszkzVSx4...\n",
      "Fetching comments for video: OMTszkzVSx4...\n",
      "✅ 100 comments fetched so far for OMTszkzVSx4\n",
      "✅ 200 comments fetched so far for OMTszkzVSx4\n",
      "✅ 300 comments fetched so far for OMTszkzVSx4\n",
      "✅ 400 comments fetched so far for OMTszkzVSx4\n",
      "✅ 500 comments fetched so far for OMTszkzVSx4\n",
      "✅ 600 comments fetched so far for OMTszkzVSx4\n",
      "✅ 700 comments fetched so far for OMTszkzVSx4\n",
      "✅ 707 comments fetched so far for OMTszkzVSx4\n",
      "Fetching metadata for video: hFw-GYAlJHc...\n",
      "Fetching comments for video: hFw-GYAlJHc...\n",
      "✅ 100 comments fetched so far for hFw-GYAlJHc\n",
      "✅ 200 comments fetched so far for hFw-GYAlJHc\n",
      "✅ 300 comments fetched so far for hFw-GYAlJHc\n",
      "✅ 400 comments fetched so far for hFw-GYAlJHc\n",
      "✅ 500 comments fetched so far for hFw-GYAlJHc\n",
      "✅ 584 comments fetched so far for hFw-GYAlJHc\n",
      "Fetching metadata for video: l9XuvDXJlZI...\n",
      "Fetching comments for video: l9XuvDXJlZI...\n",
      "✅ 100 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 200 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 300 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 400 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 500 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 600 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 700 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 800 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 900 comments fetched so far for l9XuvDXJlZI\n",
      "✅ 940 comments fetched so far for l9XuvDXJlZI\n",
      "Fetching metadata for video: y4vOuRv9jyA...\n",
      "Fetching comments for video: y4vOuRv9jyA...\n",
      "✅ 100 comments fetched so far for y4vOuRv9jyA\n",
      "✅ 200 comments fetched so far for y4vOuRv9jyA\n",
      "✅ 300 comments fetched so far for y4vOuRv9jyA\n",
      "✅ 332 comments fetched so far for y4vOuRv9jyA\n",
      "Fetching metadata for video: KrmqY9hyCCw...\n",
      "Fetching comments for video: KrmqY9hyCCw...\n",
      "✅ 100 comments fetched so far for KrmqY9hyCCw\n",
      "✅ 200 comments fetched so far for KrmqY9hyCCw\n",
      "✅ 291 comments fetched so far for KrmqY9hyCCw\n",
      "Fetching metadata for video: jNdQb-958hA...\n",
      "Fetching comments for video: jNdQb-958hA...\n",
      "✅ 100 comments fetched so far for jNdQb-958hA\n",
      "✅ 200 comments fetched so far for jNdQb-958hA\n",
      "✅ 300 comments fetched so far for jNdQb-958hA\n",
      "✅ 400 comments fetched so far for jNdQb-958hA\n",
      "✅ 500 comments fetched so far for jNdQb-958hA\n",
      "✅ 600 comments fetched so far for jNdQb-958hA\n",
      "✅ 700 comments fetched so far for jNdQb-958hA\n",
      "✅ 800 comments fetched so far for jNdQb-958hA\n",
      "✅ 900 comments fetched so far for jNdQb-958hA\n",
      "✅ 1000 comments fetched so far for jNdQb-958hA\n",
      "✅ 1100 comments fetched so far for jNdQb-958hA\n",
      "✅ 1200 comments fetched so far for jNdQb-958hA\n",
      "✅ 1267 comments fetched so far for jNdQb-958hA\n",
      "Fetching metadata for video: gHv0Fjq3GTM...\n",
      "Fetching comments for video: gHv0Fjq3GTM...\n",
      "✅ 100 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 200 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 300 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 400 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 500 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 600 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 700 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 800 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 900 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 1000 comments fetched so far for gHv0Fjq3GTM\n",
      "✅ 1099 comments fetched so far for gHv0Fjq3GTM\n",
      "Fetching metadata for video: YCMIwOvegak...\n",
      "Fetching comments for video: YCMIwOvegak...\n",
      "✅ 33 comments fetched so far for YCMIwOvegak\n",
      "Fetching metadata for video: dGEC3CMp0hE...\n",
      "Fetching comments for video: dGEC3CMp0hE...\n",
      "✅ 100 comments fetched so far for dGEC3CMp0hE\n",
      "✅ 190 comments fetched so far for dGEC3CMp0hE\n",
      "Fetching metadata for video: Z_3t4Me-USY...\n",
      "Fetching comments for video: Z_3t4Me-USY...\n",
      "✅ 56 comments fetched so far for Z_3t4Me-USY\n",
      "Fetching metadata for video: K1LnvaVRwx8...\n",
      "Fetching comments for video: K1LnvaVRwx8...\n",
      "✅ 100 comments fetched so far for K1LnvaVRwx8\n",
      "✅ 158 comments fetched so far for K1LnvaVRwx8\n",
      "Fetching metadata for video: bG33XKc67mw...\n",
      "Fetching comments for video: bG33XKc67mw...\n",
      "✅ 54 comments fetched so far for bG33XKc67mw\n",
      "Fetching metadata for video: 0TloNP2_f-0...\n",
      "Fetching comments for video: 0TloNP2_f-0...\n",
      "✅ 100 comments fetched so far for 0TloNP2_f-0\n",
      "\n",
      "✅ Total Comments Retrieved: 5811\n",
      "📂 All data saved to 'All_Events.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of YouTube video IDs that cover multiple sportswashing events\n",
    "VIDEO_IDS = [\n",
    "    \"OMTszkzVSx4\", \"hFw-GYAlJHc\", \"l9XuvDXJlZI\", \"y4vOuRv9jyA\", \"KrmqY9hyCCw\",\n",
    "    \"jNdQb-958hA\", \"gHv0Fjq3GTM\", \"YCMIwOvegak\", \"dGEC3CMp0hE\", \"Z_3t4Me-USY\",\n",
    "    \"K1LnvaVRwx8\", \"bG33XKc67mw\", \"0TloNP2_f-0\"\n",
    "]\n",
    "\n",
    "# Get a dictionary of YouTube category IDs mapped to readable names\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "# Building the category map to use later\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# Name of the output CSV file where everything will be stored\n",
    "OUTPUT_FILE = \"All_Events.csv\"\n",
    "\n",
    "# Check if the file already exists (so we know whether to write headers)\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Open the CSV in append mode so we don’t overwrite previous data\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # If it’s a new file, write the column headers\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Running total of all comments collected\n",
    "\n",
    "    # Loop through each video ID one by one\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Pull video-level metadata: title, channel, category ID\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                # No metadata found — move on to the next video\n",
    "                print(f\"No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            # Metadata request failed — skip this video\n",
    "            print(f\"Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Set up the API call to fetch top-level comments\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0  # Track per-video comment count\n",
    "\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    # Write the full row of comment + video metadata to the file\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "\n",
    "                # If there’s a next page of comments, build the next URL\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                # Comment request failed — stop for this video\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            # Add a short delay to stay within API rate limits\n",
    "            time.sleep(1)\n",
    "\n",
    "# Final output message once all videos are processed\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de6ac1-14cc-4342-b950-649d844e4d50",
   "metadata": {},
   "source": [
    "## LIV Golf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a7721-3fa1-401e-872a-d7a1fed7c059",
   "metadata": {},
   "source": [
    "This section collects public YouTube comments related to the **LIV Golf Series**.  \n",
    "It uses the YouTube Data API to:\n",
    "\n",
    "- Fetch video metadata (title, category, channel)\n",
    "- Extract top-level comments and engagement info (likes, replies)\n",
    "- Save all output into a structured `.csv` file for later processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8cc307-8b42-4fce-9c0e-a6db44f14063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: mYGTNHfgZ8E...\n",
      "Fetching comments for video: mYGTNHfgZ8E...\n",
      "✅ 100 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 200 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 300 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 400 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 500 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 600 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 700 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 800 comments fetched so far for mYGTNHfgZ8E\n",
      "✅ 803 comments fetched so far for mYGTNHfgZ8E\n",
      "Fetching metadata for video: Heo_bESl4cc...\n",
      "Fetching comments for video: Heo_bESl4cc...\n",
      "✅ 100 comments fetched so far for Heo_bESl4cc\n",
      "✅ 200 comments fetched so far for Heo_bESl4cc\n",
      "✅ 214 comments fetched so far for Heo_bESl4cc\n",
      "Fetching metadata for video: GSJUgWgtDpU...\n",
      "Fetching comments for video: GSJUgWgtDpU...\n",
      "✅ 100 comments fetched so far for GSJUgWgtDpU\n",
      "✅ 200 comments fetched so far for GSJUgWgtDpU\n",
      "✅ 300 comments fetched so far for GSJUgWgtDpU\n",
      "✅ 400 comments fetched so far for GSJUgWgtDpU\n",
      "✅ 454 comments fetched so far for GSJUgWgtDpU\n",
      "Fetching metadata for video: xKw_YRXTmCs...\n",
      "Fetching comments for video: xKw_YRXTmCs...\n",
      "✅ 100 comments fetched so far for xKw_YRXTmCs\n",
      "✅ 200 comments fetched so far for xKw_YRXTmCs\n",
      "✅ 207 comments fetched so far for xKw_YRXTmCs\n",
      "Fetching metadata for video: aHtdkOeOUHs...\n",
      "Fetching comments for video: aHtdkOeOUHs...\n",
      "✅ 100 comments fetched so far for aHtdkOeOUHs\n",
      "✅ 200 comments fetched so far for aHtdkOeOUHs\n",
      "✅ 207 comments fetched so far for aHtdkOeOUHs\n",
      "Fetching metadata for video: D9KQDzyheUI...\n",
      "Fetching comments for video: D9KQDzyheUI...\n",
      "✅ 100 comments fetched so far for D9KQDzyheUI\n",
      "✅ 200 comments fetched so far for D9KQDzyheUI\n",
      "✅ 300 comments fetched so far for D9KQDzyheUI\n",
      "✅ 400 comments fetched so far for D9KQDzyheUI\n",
      "✅ 500 comments fetched so far for D9KQDzyheUI\n",
      "✅ 600 comments fetched so far for D9KQDzyheUI\n",
      "✅ 700 comments fetched so far for D9KQDzyheUI\n",
      "✅ 800 comments fetched so far for D9KQDzyheUI\n",
      "✅ 900 comments fetched so far for D9KQDzyheUI\n",
      "✅ 1000 comments fetched so far for D9KQDzyheUI\n",
      "✅ 1100 comments fetched so far for D9KQDzyheUI\n",
      "✅ 1200 comments fetched so far for D9KQDzyheUI\n",
      "✅ 1300 comments fetched so far for D9KQDzyheUI\n",
      "✅ 1400 comments fetched so far for D9KQDzyheUI\n",
      "✅ 1493 comments fetched so far for D9KQDzyheUI\n",
      "Fetching metadata for video: nuGBJOq_aCI...\n",
      "Fetching comments for video: nuGBJOq_aCI...\n",
      "✅ 100 comments fetched so far for nuGBJOq_aCI\n",
      "✅ 200 comments fetched so far for nuGBJOq_aCI\n",
      "✅ 300 comments fetched so far for nuGBJOq_aCI\n",
      "✅ 364 comments fetched so far for nuGBJOq_aCI\n",
      "Fetching metadata for video: cU9rmNPdn-Q...\n",
      "Fetching comments for video: cU9rmNPdn-Q...\n",
      "✅ 4 comments fetched so far for cU9rmNPdn-Q\n",
      "Fetching metadata for video: gspb4DSvgm8...\n",
      "Fetching comments for video: gspb4DSvgm8...\n",
      "✅ 100 comments fetched so far for gspb4DSvgm8\n",
      "✅ 200 comments fetched so far for gspb4DSvgm8\n",
      "✅ 300 comments fetched so far for gspb4DSvgm8\n",
      "✅ 400 comments fetched so far for gspb4DSvgm8\n",
      "✅ 480 comments fetched so far for gspb4DSvgm8\n",
      "Fetching metadata for video: c8AQMWnvj_Q...\n",
      "Fetching comments for video: c8AQMWnvj_Q...\n",
      "✅ 100 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 200 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 300 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 400 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 500 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 600 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 700 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 800 comments fetched so far for c8AQMWnvj_Q\n",
      "✅ 887 comments fetched so far for c8AQMWnvj_Q\n",
      "Fetching metadata for video: zv9jyz3lauo...\n",
      "Fetching comments for video: zv9jyz3lauo...\n",
      "✅ 100 comments fetched so far for zv9jyz3lauo\n",
      "✅ 200 comments fetched so far for zv9jyz3lauo\n",
      "✅ 300 comments fetched so far for zv9jyz3lauo\n",
      "✅ 400 comments fetched so far for zv9jyz3lauo\n",
      "✅ 500 comments fetched so far for zv9jyz3lauo\n",
      "✅ 600 comments fetched so far for zv9jyz3lauo\n",
      "✅ 615 comments fetched so far for zv9jyz3lauo\n",
      "Fetching metadata for video: ZQwFsV3vk54...\n",
      "Fetching comments for video: ZQwFsV3vk54...\n",
      "✅ 100 comments fetched so far for ZQwFsV3vk54\n",
      "✅ 200 comments fetched so far for ZQwFsV3vk54\n",
      "✅ 232 comments fetched so far for ZQwFsV3vk54\n",
      "Fetching metadata for video: dqqgE85y6rM...\n",
      "Fetching comments for video: dqqgE85y6rM...\n",
      "✅ 100 comments fetched so far for dqqgE85y6rM\n",
      "✅ 200 comments fetched so far for dqqgE85y6rM\n",
      "✅ 250 comments fetched so far for dqqgE85y6rM\n",
      "Fetching metadata for video: f6cmTZQ5CUw...\n",
      "Fetching comments for video: f6cmTZQ5CUw...\n",
      "✅ 19 comments fetched so far for f6cmTZQ5CUw\n",
      "\n",
      "✅ Total Comments Retrieved: 6229\n",
      "📂 All data saved to 'LIV_Golf.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of YouTube Video IDs\n",
    "VIDEO_IDS = [\n",
    "    \"mYGTNHfgZ8E\", \"Heo_bESl4cc\", \"GSJUgWgtDpU\", \"xKw_YRXTmCs\", \"aHtdkOeOUHs\",\n",
    "    \"D9KQDzyheUI\", \"nuGBJOq_aCI\", \"cU9rmNPdn-Q\", \"gspb4DSvgm8\", \"c8AQMWnvj_Q\",\n",
    "    \"zv9jyz3lauo\", \"ZQwFsV3vk54\", \"dqqgE85y6rM\", \"f6cmTZQ5CUw\"\n",
    "]\n",
    "\n",
    "# Map YouTube Category IDs to Names\n",
    "# This function queries YouTube API to build a dictionary like {\"24\": \"Entertainment\"}\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "# Create full mapping of category IDs to readable names\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# CSV file to store all comments\n",
    "OUTPUT_FILE = \"LIV_Golf.csv\"\n",
    "\n",
    "# Check if the file exists to avoid rewriting the header\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Opening CSV file in \"append mode\" to keep adding data\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Write header only if the file is newly created\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Track total comments collected\n",
    "\n",
    "    # Loop through each video in the list\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Pull metadata like title, channel name, and category ID\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                # If no snippet found, skip this video\n",
    "                print(f\"No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            # If metadata fetch fails, skip to next video\n",
    "            print(f\"Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Prepare API URL to get comment threads\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0  # Track number of comments collected for this video\n",
    "\n",
    "        # Paginate through comment pages\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "\n",
    "                # Loop through each top-level comment\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    # Save one row per comment in the CSV file\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "\n",
    "                # Check if there's another page of comments\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                # If the comment fetch fails, move to the next video\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            # Sleep to stay within API rate limits\n",
    "            time.sleep(1)\n",
    "\n",
    "# Summary printout\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00857e9b-9694-4f51-9505-cb3d032f7750",
   "metadata": {},
   "source": [
    "## Manchester City Ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072e6bd-451a-49fd-b7ef-371cebb739bb",
   "metadata": {},
   "source": [
    "This section collects public YouTube comments related to **Manchester City's ownership and financial backing**.  \n",
    "It uses the YouTube Data API to:\n",
    "\n",
    "- Retrieve video metadata (title, category, channel)\n",
    "- Extract top-level comments along with engagement info (likes, replies)\n",
    "- Save all output into a structured `.csv` file for later processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dcfe61c-bb32-4732-acd4-e5d40d98bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: _VXzl5S0sUA...\n",
      "Fetching comments for video: _VXzl5S0sUA...\n",
      "✅ 100 comments fetched so far for _VXzl5S0sUA\n",
      "✅ 121 comments fetched so far for _VXzl5S0sUA\n",
      "Fetching metadata for video: t9IK5MDb9zk...\n",
      "Fetching comments for video: t9IK5MDb9zk...\n",
      "✅ 100 comments fetched so far for t9IK5MDb9zk\n",
      "✅ 200 comments fetched so far for t9IK5MDb9zk\n",
      "✅ 300 comments fetched so far for t9IK5MDb9zk\n",
      "✅ 384 comments fetched so far for t9IK5MDb9zk\n",
      "Fetching metadata for video: mWJXuDTaeX4...\n",
      "Fetching comments for video: mWJXuDTaeX4...\n",
      "✅ 100 comments fetched so far for mWJXuDTaeX4\n",
      "✅ 200 comments fetched so far for mWJXuDTaeX4\n",
      "✅ 300 comments fetched so far for mWJXuDTaeX4\n",
      "✅ 400 comments fetched so far for mWJXuDTaeX4\n",
      "✅ 500 comments fetched so far for mWJXuDTaeX4\n",
      "✅ 600 comments fetched so far for mWJXuDTaeX4\n",
      "✅ 700 comments fetched so far for mWJXuDTaeX4\n",
      "✅ 727 comments fetched so far for mWJXuDTaeX4\n",
      "Fetching metadata for video: 9LMNKJO8bH8...\n",
      "Fetching comments for video: 9LMNKJO8bH8...\n",
      "✅ 70 comments fetched so far for 9LMNKJO8bH8\n",
      "Fetching metadata for video: Z0HWQatIXK8...\n",
      "Fetching comments for video: Z0HWQatIXK8...\n",
      "✅ 100 comments fetched so far for Z0HWQatIXK8\n",
      "✅ 200 comments fetched so far for Z0HWQatIXK8\n",
      "✅ 290 comments fetched so far for Z0HWQatIXK8\n",
      "Fetching metadata for video: -ugz3j9I-80...\n",
      "Fetching comments for video: -ugz3j9I-80...\n",
      "✅ 100 comments fetched so far for -ugz3j9I-80\n",
      "✅ 129 comments fetched so far for -ugz3j9I-80\n",
      "Fetching metadata for video: WGyomoSnP-A...\n",
      "Fetching comments for video: WGyomoSnP-A...\n",
      "✅ 100 comments fetched so far for WGyomoSnP-A\n",
      "✅ 152 comments fetched so far for WGyomoSnP-A\n",
      "Fetching metadata for video: yDjISzW4QDk...\n",
      "Fetching comments for video: yDjISzW4QDk...\n",
      "✅ 100 comments fetched so far for yDjISzW4QDk\n",
      "✅ 200 comments fetched so far for yDjISzW4QDk\n",
      "✅ 300 comments fetched so far for yDjISzW4QDk\n",
      "✅ 400 comments fetched so far for yDjISzW4QDk\n",
      "✅ 500 comments fetched so far for yDjISzW4QDk\n",
      "✅ 600 comments fetched so far for yDjISzW4QDk\n",
      "✅ 622 comments fetched so far for yDjISzW4QDk\n",
      "Fetching metadata for video: hbkCDZcMeLA...\n",
      "Fetching comments for video: hbkCDZcMeLA...\n",
      "✅ 100 comments fetched so far for hbkCDZcMeLA\n",
      "✅ 200 comments fetched so far for hbkCDZcMeLA\n",
      "✅ 300 comments fetched so far for hbkCDZcMeLA\n",
      "✅ 400 comments fetched so far for hbkCDZcMeLA\n",
      "✅ 500 comments fetched so far for hbkCDZcMeLA\n",
      "✅ 600 comments fetched so far for hbkCDZcMeLA\n",
      "✅ 677 comments fetched so far for hbkCDZcMeLA\n",
      "Fetching metadata for video: mBgDXoB2cms...\n",
      "Fetching comments for video: mBgDXoB2cms...\n",
      "✅ 100 comments fetched so far for mBgDXoB2cms\n",
      "✅ 108 comments fetched so far for mBgDXoB2cms\n",
      "Fetching metadata for video: Bs9l0SaXJhs...\n",
      "Fetching comments for video: Bs9l0SaXJhs...\n",
      "✅ 100 comments fetched so far for Bs9l0SaXJhs\n",
      "✅ 200 comments fetched so far for Bs9l0SaXJhs\n",
      "✅ 245 comments fetched so far for Bs9l0SaXJhs\n",
      "Fetching metadata for video: Fifh6otxBII...\n",
      "Fetching comments for video: Fifh6otxBII...\n",
      "✅ 100 comments fetched so far for Fifh6otxBII\n",
      "✅ 200 comments fetched so far for Fifh6otxBII\n",
      "✅ 300 comments fetched so far for Fifh6otxBII\n",
      "✅ 316 comments fetched so far for Fifh6otxBII\n",
      "Fetching metadata for video: hPmf0oSGZtM...\n",
      "Fetching comments for video: hPmf0oSGZtM...\n",
      "✅ 100 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 200 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 300 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 400 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 500 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 600 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 700 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 800 comments fetched so far for hPmf0oSGZtM\n",
      "✅ 882 comments fetched so far for hPmf0oSGZtM\n",
      "Fetching metadata for video: CF_0c3hRV9w...\n",
      "Fetching comments for video: CF_0c3hRV9w...\n",
      "✅ 100 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 200 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 300 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 400 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 500 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 600 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 700 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 800 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 900 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 1000 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 1100 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 1200 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 1300 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 1400 comments fetched so far for CF_0c3hRV9w\n",
      "✅ 1470 comments fetched so far for CF_0c3hRV9w\n",
      "Fetching metadata for video: AwC1J9o9Wxk...\n",
      "Fetching comments for video: AwC1J9o9Wxk...\n",
      "✅ 100 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 200 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 300 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 400 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 500 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 600 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 700 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 800 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 900 comments fetched so far for AwC1J9o9Wxk\n",
      "✅ 942 comments fetched so far for AwC1J9o9Wxk\n",
      "Fetching metadata for video: t1dRiZJsXDY...\n",
      "Fetching comments for video: t1dRiZJsXDY...\n",
      "✅ 100 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 200 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 300 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 400 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 500 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 600 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 700 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 800 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 900 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 1000 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 1100 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 1200 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 1300 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 1400 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 1500 comments fetched so far for t1dRiZJsXDY\n",
      "✅ 1575 comments fetched so far for t1dRiZJsXDY\n",
      "Fetching metadata for video: tNdOw-yNIUM...\n",
      "Fetching comments for video: tNdOw-yNIUM...\n",
      "✅ 100 comments fetched so far for tNdOw-yNIUM\n",
      "✅ 200 comments fetched so far for tNdOw-yNIUM\n",
      "✅ 300 comments fetched so far for tNdOw-yNIUM\n",
      "✅ 400 comments fetched so far for tNdOw-yNIUM\n",
      "✅ 500 comments fetched so far for tNdOw-yNIUM\n",
      "✅ 600 comments fetched so far for tNdOw-yNIUM\n",
      "✅ 687 comments fetched so far for tNdOw-yNIUM\n",
      "Fetching metadata for video: lhiwDz4k6g4...\n",
      "Fetching comments for video: lhiwDz4k6g4...\n",
      "✅ 100 comments fetched so far for lhiwDz4k6g4\n",
      "✅ 200 comments fetched so far for lhiwDz4k6g4\n",
      "✅ 264 comments fetched so far for lhiwDz4k6g4\n",
      "Fetching metadata for video: 1o7i2jrQiZY...\n",
      "Fetching comments for video: 1o7i2jrQiZY...\n",
      "✅ 100 comments fetched so far for 1o7i2jrQiZY\n",
      "✅ 200 comments fetched so far for 1o7i2jrQiZY\n",
      "✅ 300 comments fetched so far for 1o7i2jrQiZY\n",
      "✅ 400 comments fetched so far for 1o7i2jrQiZY\n",
      "✅ 500 comments fetched so far for 1o7i2jrQiZY\n",
      "✅ 600 comments fetched so far for 1o7i2jrQiZY\n",
      "✅ 700 comments fetched so far for 1o7i2jrQiZY\n",
      "Fetching metadata for video: 7jVQRBO3QC0...\n",
      "Fetching comments for video: 7jVQRBO3QC0...\n",
      "✅ 100 comments fetched so far for 7jVQRBO3QC0\n",
      "✅ 200 comments fetched so far for 7jVQRBO3QC0\n",
      "✅ 226 comments fetched so far for 7jVQRBO3QC0\n",
      "Fetching metadata for video: WkU3mtm1ygI...\n",
      "Fetching comments for video: WkU3mtm1ygI...\n",
      "✅ 100 comments fetched so far for WkU3mtm1ygI\n",
      "✅ 200 comments fetched so far for WkU3mtm1ygI\n",
      "✅ 300 comments fetched so far for WkU3mtm1ygI\n",
      "✅ 400 comments fetched so far for WkU3mtm1ygI\n",
      "✅ 445 comments fetched so far for WkU3mtm1ygI\n",
      "\n",
      "✅ Total Comments Retrieved: 11032\n",
      "📂 All data saved to 'Manchester_City_Ownership.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of YouTube Video IDs related to Manchester City's ownership\n",
    "VIDEO_IDS = [\n",
    "    \"_VXzl5S0sUA\", \"t9IK5MDb9zk\", \"mWJXuDTaeX4\", \"9LMNKJO8bH8\", \"Z0HWQatIXK8\",\n",
    "    \"-ugz3j9I-80\", \"WGyomoSnP-A\", \"yDjISzW4QDk\", \"hbkCDZcMeLA\", \"mBgDXoB2cms\",\n",
    "    \"Bs9l0SaXJhs\", \"Fifh6otxBII\", \"hPmf0oSGZtM\", \"CF_0c3hRV9w\", \"AwC1J9o9Wxk\",\n",
    "    \"t1dRiZJsXDY\", \"tNdOw-yNIUM\", \"lhiwDz4k6g4\", \"1o7i2jrQiZY\", \"7jVQRBO3QC0\",\n",
    "    \"WkU3mtm1ygI\"\n",
    "]\n",
    "\n",
    "# Function to retrieve a mapping from category IDs to human-readable names\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "# Build the mapping once so it can be reused\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# Output file for all comments in this section\n",
    "OUTPUT_FILE = \"Manchester_City_Ownership.csv\"\n",
    "\n",
    "# Check if the output file already exists so we don’t re-write the header\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Open the CSV file in append mode — so it doesn't overwrite previous runs\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # If the file is new, write the header row\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Total number of comments collected across all videos\n",
    "\n",
    "    # Loop over each video\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Step 1: Get video-level metadata\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                print(f\" No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\" Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "\n",
    "        # Step 2: Begin fetching top-level comments (up to 100 at a time)\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0\n",
    "\n",
    "        # Continue paginating through all available comment pages\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    # Save extracted comment and metadata to CSV\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "\n",
    "                # Get next page if available\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            # Slight delay between requests to avoid rate limiting\n",
    "            time.sleep(1)\n",
    "\n",
    "# Final log output\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92bde5a-a6e6-4a15-937f-7a8b0d5ec67d",
   "metadata": {},
   "source": [
    "## PSG Ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a9acb-10d5-4dfe-842b-e3e09be428d2",
   "metadata": {},
   "source": [
    "This section collects public YouTube comments related to **Paris Saint-Germain's ownership and its links to Qatar**.  \n",
    "It uses the YouTube Data API to:\n",
    "\n",
    "- Fetch video metadata (title, category, channel)\n",
    "- Extract top-level comments and engagement details (likes, replies)\n",
    "- Save all output into a structured `.csv` file for later processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c3e4298-5de5-4fb8-9e8b-26b462daa100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: Dvh2M8lONLk...\n",
      "Fetching comments for video: Dvh2M8lONLk...\n",
      "✅ 100 comments fetched so far for Dvh2M8lONLk\n",
      "✅ 193 comments fetched so far for Dvh2M8lONLk\n",
      "Fetching metadata for video: _tYH4_tmktA...\n",
      "Fetching comments for video: _tYH4_tmktA...\n",
      "✅ 100 comments fetched so far for _tYH4_tmktA\n",
      "✅ 200 comments fetched so far for _tYH4_tmktA\n",
      "✅ 231 comments fetched so far for _tYH4_tmktA\n",
      "Fetching metadata for video: 224pbl296dI...\n",
      "Fetching comments for video: 224pbl296dI...\n",
      "✅ 100 comments fetched so far for 224pbl296dI\n",
      "✅ 200 comments fetched so far for 224pbl296dI\n",
      "✅ 300 comments fetched so far for 224pbl296dI\n",
      "✅ 375 comments fetched so far for 224pbl296dI\n",
      "Fetching metadata for video: aUpfkl_rWGs...\n",
      "Fetching comments for video: aUpfkl_rWGs...\n",
      "✅ 14 comments fetched so far for aUpfkl_rWGs\n",
      "Fetching metadata for video: 7TJrf1OtsJA...\n",
      "Fetching comments for video: 7TJrf1OtsJA...\n",
      "✅ 55 comments fetched so far for 7TJrf1OtsJA\n",
      "Fetching metadata for video: 4q0hpZD3Y8Q...\n",
      "Fetching comments for video: 4q0hpZD3Y8Q...\n",
      "✅ 28 comments fetched so far for 4q0hpZD3Y8Q\n",
      "Fetching metadata for video: KKgxVwMtsZc...\n",
      "Fetching comments for video: KKgxVwMtsZc...\n",
      "✅ 100 comments fetched so far for KKgxVwMtsZc\n",
      "✅ 200 comments fetched so far for KKgxVwMtsZc\n",
      "✅ 252 comments fetched so far for KKgxVwMtsZc\n",
      "Fetching metadata for video: lBRMtyrW184...\n",
      "Fetching comments for video: lBRMtyrW184...\n",
      "✅ 100 comments fetched so far for lBRMtyrW184\n",
      "✅ 132 comments fetched so far for lBRMtyrW184\n",
      "\n",
      "✅ Total Comments Retrieved: 1280\n",
      "📂 All data saved to 'PSG_Ownership.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of YouTube Video IDs\n",
    "VIDEO_IDS = [\n",
    "    \"Dvh2M8lONLk\", \"_tYH4_tmktA\", \"224pbl296dI\", \"aUpfkl_rWGs\", \"7TJrf1OtsJA\",\n",
    "    \"4q0hpZD3Y8Q\", \"KKgxVwMtsZc\", \"lBRMtyrW184\"\n",
    "]\n",
    "\n",
    "# Map YouTube Category IDs to Names\n",
    "# Pulls a dictionary that maps category IDs (e.g. 17) to actual names (e.g. Sports).\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# Everything gets saved here for later analysis.\n",
    "OUTPUT_FILE = \"PSG_Ownership.csv\"\n",
    "\n",
    "# Check if the file exists to avoid rewriting the header\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Open CSV file in append mode so existing data stays intact\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Add header only if this is the first time creating the file\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Track how many comments we collect\n",
    "\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "        # Get the title, category, and channel for the video\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                print(f\"No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "        # Pull top-level comments and basic engagement info\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0\n",
    "\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    # Add comment to CSV with all metadata\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "                # If there’s a next page of comments, update the URL\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715ce8a-306e-4c59-a16c-e0f0e8fb4e9f",
   "metadata": {},
   "source": [
    "## Saudi Pro League"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f499907-c3b6-4d9e-b4b0-ea399282023e",
   "metadata": {},
   "source": [
    "This section collects public YouTube comments related to the **Saudi Pro League and its recent high-profile investments**.  \n",
    "It uses the YouTube Data API to:\n",
    "\n",
    "- Fetch video metadata (title, category, channel)  \n",
    "- Extract top-level comments and engagement details (likes, replies)  \n",
    "- Save all output into a structured `.csv` file for later processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ea33d4-1c90-467c-b0ed-d995ca430f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: LZn3i2YZ1BA...\n",
      "Fetching comments for video: LZn3i2YZ1BA...\n",
      "✅ 100 comments fetched so far for LZn3i2YZ1BA\n",
      "✅ 200 comments fetched so far for LZn3i2YZ1BA\n",
      "✅ 300 comments fetched so far for LZn3i2YZ1BA\n",
      "✅ 400 comments fetched so far for LZn3i2YZ1BA\n",
      "✅ 500 comments fetched so far for LZn3i2YZ1BA\n",
      "✅ 600 comments fetched so far for LZn3i2YZ1BA\n",
      "✅ 691 comments fetched so far for LZn3i2YZ1BA\n",
      "Fetching metadata for video: _mE9K20hqSQ...\n",
      "Fetching comments for video: _mE9K20hqSQ...\n",
      "✅ 100 comments fetched so far for _mE9K20hqSQ\n",
      "✅ 200 comments fetched so far for _mE9K20hqSQ\n",
      "✅ 300 comments fetched so far for _mE9K20hqSQ\n",
      "✅ 400 comments fetched so far for _mE9K20hqSQ\n",
      "✅ 500 comments fetched so far for _mE9K20hqSQ\n",
      "✅ 600 comments fetched so far for _mE9K20hqSQ\n",
      "✅ 700 comments fetched so far for _mE9K20hqSQ\n",
      "✅ 712 comments fetched so far for _mE9K20hqSQ\n",
      "Fetching metadata for video: B9OZWppefsA...\n",
      "Fetching comments for video: B9OZWppefsA...\n",
      "✅ 42 comments fetched so far for B9OZWppefsA\n",
      "Fetching metadata for video: 21RnbXFTMQ0...\n",
      "Fetching comments for video: 21RnbXFTMQ0...\n",
      "✅ 100 comments fetched so far for 21RnbXFTMQ0\n",
      "✅ 200 comments fetched so far for 21RnbXFTMQ0\n",
      "✅ 300 comments fetched so far for 21RnbXFTMQ0\n",
      "✅ 363 comments fetched so far for 21RnbXFTMQ0\n",
      "Fetching metadata for video: 5slVNMFT0_g...\n",
      "Fetching comments for video: 5slVNMFT0_g...\n",
      "✅ 100 comments fetched so far for 5slVNMFT0_g\n",
      "✅ 200 comments fetched so far for 5slVNMFT0_g\n",
      "✅ 208 comments fetched so far for 5slVNMFT0_g\n",
      "Fetching metadata for video: PmRQlxjUcOI...\n",
      "Fetching comments for video: PmRQlxjUcOI...\n",
      "✅ 100 comments fetched so far for PmRQlxjUcOI\n",
      "✅ 200 comments fetched so far for PmRQlxjUcOI\n",
      "✅ 300 comments fetched so far for PmRQlxjUcOI\n",
      "✅ 400 comments fetched so far for PmRQlxjUcOI\n",
      "✅ 449 comments fetched so far for PmRQlxjUcOI\n",
      "Fetching metadata for video: KVFterzsmOg...\n",
      "Fetching comments for video: KVFterzsmOg...\n",
      "✅ 100 comments fetched so far for KVFterzsmOg\n",
      "✅ 200 comments fetched so far for KVFterzsmOg\n",
      "✅ 300 comments fetched so far for KVFterzsmOg\n",
      "✅ 400 comments fetched so far for KVFterzsmOg\n",
      "✅ 500 comments fetched so far for KVFterzsmOg\n",
      "✅ 600 comments fetched so far for KVFterzsmOg\n",
      "✅ 700 comments fetched so far for KVFterzsmOg\n",
      "✅ 800 comments fetched so far for KVFterzsmOg\n",
      "✅ 900 comments fetched so far for KVFterzsmOg\n",
      "✅ 1000 comments fetched so far for KVFterzsmOg\n",
      "✅ 1022 comments fetched so far for KVFterzsmOg\n",
      "Fetching metadata for video: hhDaKszN-zA...\n",
      "Fetching comments for video: hhDaKszN-zA...\n",
      "✅ 100 comments fetched so far for hhDaKszN-zA\n",
      "✅ 200 comments fetched so far for hhDaKszN-zA\n",
      "✅ 300 comments fetched so far for hhDaKszN-zA\n",
      "✅ 400 comments fetched so far for hhDaKszN-zA\n",
      "✅ 500 comments fetched so far for hhDaKszN-zA\n",
      "✅ 577 comments fetched so far for hhDaKszN-zA\n",
      "Fetching metadata for video: wvEw-ozrZNU...\n",
      "Fetching comments for video: wvEw-ozrZNU...\n",
      "✅ 30 comments fetched so far for wvEw-ozrZNU\n",
      "Fetching metadata for video: MJxsx9CcnZc...\n",
      "Fetching comments for video: MJxsx9CcnZc...\n",
      "✅ 100 comments fetched so far for MJxsx9CcnZc\n",
      "✅ 200 comments fetched so far for MJxsx9CcnZc\n",
      "✅ 300 comments fetched so far for MJxsx9CcnZc\n",
      "✅ 400 comments fetched so far for MJxsx9CcnZc\n",
      "✅ 500 comments fetched so far for MJxsx9CcnZc\n",
      "✅ 599 comments fetched so far for MJxsx9CcnZc\n",
      "Fetching metadata for video: GUuDJIr3FUs...\n",
      "Fetching comments for video: GUuDJIr3FUs...\n",
      "✅ 100 comments fetched so far for GUuDJIr3FUs\n",
      "✅ 200 comments fetched so far for GUuDJIr3FUs\n",
      "✅ 213 comments fetched so far for GUuDJIr3FUs\n",
      "Fetching metadata for video: wtQ4K7zcPkw...\n",
      "Fetching comments for video: wtQ4K7zcPkw...\n",
      "✅ 100 comments fetched so far for wtQ4K7zcPkw\n",
      "✅ 200 comments fetched so far for wtQ4K7zcPkw\n",
      "✅ 300 comments fetched so far for wtQ4K7zcPkw\n",
      "✅ 306 comments fetched so far for wtQ4K7zcPkw\n",
      "Fetching metadata for video: ETaR3PvusVI...\n",
      "Fetching comments for video: ETaR3PvusVI...\n",
      "✅ 80 comments fetched so far for ETaR3PvusVI\n",
      "Fetching metadata for video: IRV4LW_V8tk...\n",
      "Fetching comments for video: IRV4LW_V8tk...\n",
      "✅ 100 comments fetched so far for IRV4LW_V8tk\n",
      "✅ 139 comments fetched so far for IRV4LW_V8tk\n",
      "Fetching metadata for video: dIfke7u5V7M...\n",
      "Fetching comments for video: dIfke7u5V7M...\n",
      "✅ 100 comments fetched so far for dIfke7u5V7M\n",
      "✅ 200 comments fetched so far for dIfke7u5V7M\n",
      "✅ 256 comments fetched so far for dIfke7u5V7M\n",
      "Fetching metadata for video: wvEw-ozrZNU...\n",
      "Fetching comments for video: wvEw-ozrZNU...\n",
      "✅ 30 comments fetched so far for wvEw-ozrZNU\n",
      "Fetching metadata for video: UNRQCksZmLo...\n",
      "Fetching comments for video: UNRQCksZmLo...\n",
      "✅ 100 comments fetched so far for UNRQCksZmLo\n",
      "✅ 200 comments fetched so far for UNRQCksZmLo\n",
      "✅ 227 comments fetched so far for UNRQCksZmLo\n",
      "Fetching metadata for video: Eiovy98OMxk...\n",
      "Fetching comments for video: Eiovy98OMxk...\n",
      "✅ 100 comments fetched so far for Eiovy98OMxk\n",
      "✅ 200 comments fetched so far for Eiovy98OMxk\n",
      "✅ 231 comments fetched so far for Eiovy98OMxk\n",
      "Fetching metadata for video: 2S5OnnuOIos...\n",
      "Fetching comments for video: 2S5OnnuOIos...\n",
      "✅ 100 comments fetched so far for 2S5OnnuOIos\n",
      "✅ 105 comments fetched so far for 2S5OnnuOIos\n",
      "Fetching metadata for video: ffAU4eXE67c...\n",
      "Fetching comments for video: ffAU4eXE67c...\n",
      "✅ 100 comments fetched so far for ffAU4eXE67c\n",
      "✅ 123 comments fetched so far for ffAU4eXE67c\n",
      "Fetching metadata for video: Al8QYC2I4qE...\n",
      "Fetching comments for video: Al8QYC2I4qE...\n",
      "✅ 100 comments fetched so far for Al8QYC2I4qE\n",
      "✅ 200 comments fetched so far for Al8QYC2I4qE\n",
      "✅ 300 comments fetched so far for Al8QYC2I4qE\n",
      "✅ 400 comments fetched so far for Al8QYC2I4qE\n",
      "✅ 500 comments fetched so far for Al8QYC2I4qE\n",
      "✅ 502 comments fetched so far for Al8QYC2I4qE\n",
      "\n",
      "✅ Total Comments Retrieved: 6905\n",
      "📂 All data saved to 'Saudi_Pro_League.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of YouTube Video IDs related to the Saudi Pro League\n",
    "VIDEO_IDS = [\n",
    "    \"LZn3i2YZ1BA\", \"_mE9K20hqSQ\", \"B9OZWppefsA\", \"21RnbXFTMQ0\", \"5slVNMFT0_g\",\n",
    "    \"PmRQlxjUcOI\", \"KVFterzsmOg\", \"hhDaKszN-zA\", \"wvEw-ozrZNU\", \"MJxsx9CcnZc\",\n",
    "    \"GUuDJIr3FUs\", \"wtQ4K7zcPkw\", \"ETaR3PvusVI\", \"IRV4LW_V8tk\", \"dIfke7u5V7M\",\n",
    "    \"wvEw-ozrZNU\", \"UNRQCksZmLo\", \"Eiovy98OMxk\", \"2S5OnnuOIos\", \"ffAU4eXE67c\",\n",
    "    \"Al8QYC2I4qE\"\n",
    "]\n",
    "\n",
    "# This maps YouTube category IDs to actual category names (e.g. Sports, News)\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# Output CSV where all extracted comments will be saved\n",
    "OUTPUT_FILE = \"Saudi_Pro_League.csv\"\n",
    "\n",
    "# Check if file already exists so we don't duplicate headers\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Open the CSV in append mode to keep adding new comments\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Only write the column names if the file was just created\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Keep track of total comments pulled\n",
    "\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                print(f\"No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0\n",
    "\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19273e9e-b5da-4b74-b980-2c5495c6b45e",
   "metadata": {},
   "source": [
    "## Formula 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c302d71-9de4-4c38-a25b-5834022c3834",
   "metadata": {},
   "source": [
    "This section collects public YouTube comments related to **Formula 1 and the middle east's role in hosting Grand Prix events**.  \n",
    "It uses the YouTube Data API to:\n",
    "\n",
    "- Fetch video metadata (title, category, channel)\n",
    "- Extract top-level comments and engagement details (likes, replies)\n",
    "- Save all output into a structured `.csv` file for later processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b5a5f08-9671-4ade-95d7-6451a7974de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for video: DLgNW9lCAaU...\n",
      "Fetching comments for video: DLgNW9lCAaU...\n",
      "✅ 100 comments fetched so far for DLgNW9lCAaU\n",
      "✅ 200 comments fetched so far for DLgNW9lCAaU\n",
      "Fetching metadata for video: r4K8V8btCtY...\n",
      "Fetching comments for video: r4K8V8btCtY...\n",
      "✅ 56 comments fetched so far for r4K8V8btCtY\n",
      "Fetching metadata for video: kRhg1dPS4Gw...\n",
      "Fetching comments for video: kRhg1dPS4Gw...\n",
      "✅ 100 comments fetched so far for kRhg1dPS4Gw\n",
      "✅ 200 comments fetched so far for kRhg1dPS4Gw\n",
      "✅ 300 comments fetched so far for kRhg1dPS4Gw\n",
      "✅ 400 comments fetched so far for kRhg1dPS4Gw\n",
      "✅ 450 comments fetched so far for kRhg1dPS4Gw\n",
      "Fetching metadata for video: Cj8wtEFNVog...\n",
      "Fetching comments for video: Cj8wtEFNVog...\n",
      "✅ 91 comments fetched so far for Cj8wtEFNVog\n",
      "Fetching metadata for video: _CLZf58vzbc...\n",
      "Fetching comments for video: _CLZf58vzbc...\n",
      "✅ 79 comments fetched so far for _CLZf58vzbc\n",
      "Fetching metadata for video: dbVki3gPYZs...\n",
      "Fetching comments for video: dbVki3gPYZs...\n",
      "✅ 100 comments fetched so far for dbVki3gPYZs\n",
      "✅ 110 comments fetched so far for dbVki3gPYZs\n",
      "Fetching metadata for video: C9sH8AD4jys...\n",
      "Fetching comments for video: C9sH8AD4jys...\n",
      "✅ 7 comments fetched so far for C9sH8AD4jys\n",
      "Fetching metadata for video: 6zEf9o-tTpc...\n",
      "Fetching comments for video: 6zEf9o-tTpc...\n",
      "✅ 100 comments fetched so far for 6zEf9o-tTpc\n",
      "✅ 200 comments fetched so far for 6zEf9o-tTpc\n",
      "✅ 247 comments fetched so far for 6zEf9o-tTpc\n",
      "Fetching metadata for video: _tSI_JV5lZY...\n",
      "Fetching comments for video: _tSI_JV5lZY...\n",
      "✅ 100 comments fetched so far for _tSI_JV5lZY\n",
      "✅ 200 comments fetched so far for _tSI_JV5lZY\n",
      "✅ 300 comments fetched so far for _tSI_JV5lZY\n",
      "✅ 307 comments fetched so far for _tSI_JV5lZY\n",
      "Fetching metadata for video: ReDGjoFTn58...\n",
      "Fetching comments for video: ReDGjoFTn58...\n",
      "✅ 28 comments fetched so far for ReDGjoFTn58\n",
      "\n",
      "✅ Total Comments Retrieved: 1575\n",
      "📂 All data saved to 'Formula_1.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of YouTube Video IDs\n",
    "VIDEO_IDS = [\n",
    "    \"DLgNW9lCAaU\", \"r4K8V8btCtY\", \"kRhg1dPS4Gw\", \"Cj8wtEFNVog\", \"_CLZf58vzbc\",\n",
    "    \"dbVki3gPYZs\", \"C9sH8AD4jys\", \"6zEf9o-tTpc\", \"_tSI_JV5lZY\", \"ReDGjoFTn58\"\n",
    "]\n",
    "\n",
    "# Map YouTube Category IDs to Names\n",
    "def get_category_mapping():\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videoCategories?part=snippet&regionCode=US&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    category_map = {}\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json().get(\"items\", [])\n",
    "        for category in categories:\n",
    "            category_id = category[\"id\"]\n",
    "            category_name = category[\"snippet\"][\"title\"]\n",
    "            category_map[category_id] = category_name\n",
    "    return category_map\n",
    "\n",
    "CATEGORY_MAPPING = get_category_mapping()\n",
    "\n",
    "# CSV file to store all comments\n",
    "OUTPUT_FILE = \"Formula_1.csv\"\n",
    "\n",
    "# Check if the file exists to avoid rewriting the header\n",
    "try:\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    file_exists = False\n",
    "\n",
    "# Open CSV file in \"append mode\" to keep adding data\n",
    "with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\n",
    "        \"Video_ID\", \"Video_Title\", \"Video_Category_Type\", \"Channel_Name\",\n",
    "        \"Comment_ID\", \"Comment\", \"Author\", \"Date\", \"Likes\", \"Replies_Count\",\n",
    "        \"Data_Source\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Write header only if the file is newly created\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total_comments = 0  # Track total comments collected\n",
    "\n",
    "    for VIDEO_ID in VIDEO_IDS:\n",
    "        print(f\"Fetching metadata for video: {VIDEO_ID}...\")\n",
    "        video_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={VIDEO_ID}&key={API_KEY}\"\n",
    "        video_response = requests.get(video_url)\n",
    "\n",
    "        if video_response.status_code == 200:\n",
    "            video_data = video_response.json()\n",
    "            if \"items\" in video_data and len(video_data[\"items\"]) > 0:\n",
    "                video_info = video_data[\"items\"][0][\"snippet\"]\n",
    "                video_title = video_info[\"title\"]\n",
    "                category_id = video_info.get(\"categoryId\", \"Unknown\")\n",
    "                video_category_type = CATEGORY_MAPPING.get(category_id, \"Unknown Category\")\n",
    "                channel_name = video_info[\"channelTitle\"]\n",
    "            else:\n",
    "                print(f\"No metadata found for video {VIDEO_ID}. Skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Failed to fetch video metadata for {VIDEO_ID}: {video_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching comments for video: {VIDEO_ID}...\")\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100\"\n",
    "        collected_comments = 0\n",
    "\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data.get(\"items\", []):\n",
    "                    snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_id = item[\"id\"]\n",
    "                    comment_text = snippet[\"textDisplay\"]\n",
    "                    author_name = snippet[\"authorDisplayName\"]\n",
    "                    published_date = snippet[\"publishedAt\"]\n",
    "                    like_count = snippet[\"likeCount\"]\n",
    "                    replies_count = item[\"snippet\"].get(\"totalReplyCount\", 0)\n",
    "\n",
    "                    writer.writerow({\n",
    "                        \"Video_ID\": VIDEO_ID,\n",
    "                        \"Video_Title\": video_title,\n",
    "                        \"Video_Category_Type\": video_category_type,\n",
    "                        \"Channel_Name\": channel_name,\n",
    "                        \"Comment_ID\": comment_id,\n",
    "                        \"Comment\": comment_text,\n",
    "                        \"Author\": author_name,\n",
    "                        \"Date\": published_date,\n",
    "                        \"Likes\": like_count,\n",
    "                        \"Replies_Count\": replies_count,\n",
    "                        \"Data_Source\": \"YouTube\"\n",
    "                    })\n",
    "\n",
    "                    total_comments += 1\n",
    "                    collected_comments += 1\n",
    "\n",
    "                print(f\"✅ {collected_comments} comments fetched so far for {VIDEO_ID}\")\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={VIDEO_ID}&key={API_KEY}&maxResults=100&pageToken={next_page_token}\" if next_page_token else None\n",
    "            else:\n",
    "                print(f\"Failed to fetch comments for {VIDEO_ID}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "print(f\"\\n✅ Total Comments Retrieved: {total_comments}\")\n",
    "print(f\"📂 All data saved to '{OUTPUT_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4305c2c1-1a59-4640-bb6b-bd1e43aca657",
   "metadata": {},
   "source": [
    "## Merging All CSV Files To Create one Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b1619ee-1bb4-47af-83cc-af245344c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged 9 files into All_YouTube_Comments.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = \"./\"  # Adjust if needed\n",
    "\n",
    "# Get list of all CSV files\n",
    "csv_files = [\n",
    "    \"All_Events.csv\",\n",
    "    \"FIFA_World_Cup_2022_Qatar.csv\",\n",
    "    \"Formula_1.csv\",\n",
    "    \"LIV_Golf.csv\",\n",
    "    \"Manchester_City_Ownership.csv\",\n",
    "    \"Newcastle_Takeover_Saudi_Arabia.csv\",\n",
    "    \"PSG_Ownership.csv\",\n",
    "    \"Saudi_Pro_League.csv\",\n",
    "    \"Qatar_Sports_Sponsorships.csv\"\n",
    "]\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Read each CSV file and append to the list\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    if os.path.exists(file_path):  \n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"Source_File\"] = file  # Add a column to indicate the original file\n",
    "        df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "if df_list:\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Save merged file\n",
    "    merged_file = \"All_YouTube_Comments.csv\"\n",
    "    merged_df.to_csv(merged_file, index=False)\n",
    "    \n",
    "    print(f\"✅ Merged {len(csv_files)} files into {merged_file}\")\n",
    "else:\n",
    "    print(\"No files found for merging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9f2aa-e533-40d1-8442-209e141e8cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
